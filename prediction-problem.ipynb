{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9b0ef-1fc5-4dd2-b9c3-5b9c25251d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data:\n",
    "# https://archive.ics.uci.edu/dataset/125/insurance+company+benchmark+coil+2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a96ea20-b5bd-498c-98cd-3dd7d9929d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aebabea-0575-4288-b9d2-70e99d704bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('insurance+company+benchmark+coil+2000/ticdata2000.txt', sep=\"\\t\", header=None)\n",
    "test = pd.read_csv('insurance+company+benchmark+coil+2000/ticeval2000.txt',sep=\"\\t\", header=None)\n",
    "target = pd.read_csv('insurance+company+benchmark+coil+2000/tictgts2000.txt', header=None)\n",
    "col = pd.read_csv('insurance+company+benchmark+coil+2000/dictionary.txt', sep= \"\\t\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d9c25b9-ac08-4ef2-9943-0af73634305d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target.columns = [\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fec9a1b-7482-4b50-a391-b2003f4f1d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_data = []\n",
    "for row in col['DATA DICTIONARY'][1:]:  \n",
    "    parts = row.split()  \n",
    "    if len(parts) > 1:  \n",
    "        name_data.append(parts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c152578f-bd2d-4db0-b862-93bcff6b2e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_col_names= name_data[:86]\n",
    "train.columns = train_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a50a6b34-b8f8-4946-8b5f-bcda81d7ecd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_col_names= name_data[:85]\n",
    "test.columns = test_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af4f315-6eb4-4e10-9d7b-bdbb71dc7068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test.info()\n",
    "# train.info()\n",
    "# There are no null values in the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3da8ba8-f453-4946-ad05-56300475a9c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>MRELGE</th>\n",
       "      <th>...</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "      <th>CARAVAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  MGODOV  \\\n",
       "0       33         1        3         2         8       0       5       1   \n",
       "1       37         1        2         2         8       1       4       1   \n",
       "2       37         1        2         2         8       0       4       2   \n",
       "3        9         1        3         3         3       2       3       2   \n",
       "4       40         1        4         2        10       1       4       1   \n",
       "\n",
       "   MGODGE  MRELGE  ...  APERSONG  AGEZONG  AWAOREG  ABRAND  AZEILPL  APLEZIER  \\\n",
       "0       3       7  ...         0        0        0       1        0         0   \n",
       "1       4       6  ...         0        0        0       1        0         0   \n",
       "2       4       3  ...         0        0        0       1        0         0   \n",
       "3       4       5  ...         0        0        0       1        0         0   \n",
       "4       4       7  ...         0        0        0       1        0         0   \n",
       "\n",
       "   AFIETS  AINBOED  ABYSTAND  CARAVAN  \n",
       "0       0        0         0        0  \n",
       "1       0        0         0        0  \n",
       "2       0        0         0        0  \n",
       "3       0        0         0        0  \n",
       "4       0        0         0        0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8218b239-22e2-4e8e-98ef-ae2f9b2c5f65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the input and target variable \n",
    "X = train.drop('CARAVAN', axis=1)  # Drop the target column 'CARAVAN'\n",
    "y = train['CARAVAN']  # Target column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc241e6b-1e68-4906-89a2-0d44e9f7ac88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode the target labels (0 and 1)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features for better training\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f27126a7-4484-41f9-a634-20feec2e461a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhavitha/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the Deep Neural Network Model using Keras\n",
    "model = Sequential()\n",
    "\n",
    "# Add input layer and first hidden layer\n",
    "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "\n",
    "# Add second hidden layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add third hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add output layer (Sigmoid activation for binary classification)\n",
    "model.add(Dense(1, activation='sigmoid')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4eec144-f759-43e2-bf69-b52077846fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9273 - loss: 0.2948 - val_accuracy: 0.9305 - val_loss: 0.2422\n",
      "Epoch 2/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9383 - loss: 0.1967 - val_accuracy: 0.9305 - val_loss: 0.2462\n",
      "Epoch 3/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9375 - loss: 0.1824 - val_accuracy: 0.9305 - val_loss: 0.2517\n",
      "Epoch 4/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9421 - loss: 0.1657 - val_accuracy: 0.9253 - val_loss: 0.2483\n",
      "Epoch 5/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9467 - loss: 0.1512 - val_accuracy: 0.9262 - val_loss: 0.2667\n",
      "Epoch 6/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9545 - loss: 0.1394 - val_accuracy: 0.9219 - val_loss: 0.2709\n",
      "Epoch 7/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9490 - loss: 0.1299 - val_accuracy: 0.9227 - val_loss: 0.2687\n",
      "Epoch 8/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9572 - loss: 0.1167 - val_accuracy: 0.9133 - val_loss: 0.2716\n",
      "Epoch 9/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9587 - loss: 0.1037 - val_accuracy: 0.9185 - val_loss: 0.2894\n",
      "Epoch 10/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9669 - loss: 0.0893 - val_accuracy: 0.9073 - val_loss: 0.3035\n",
      "Epoch 11/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9683 - loss: 0.0838 - val_accuracy: 0.9202 - val_loss: 0.3469\n",
      "Epoch 12/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9700 - loss: 0.0770 - val_accuracy: 0.9133 - val_loss: 0.3636\n",
      "Epoch 13/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9653 - loss: 0.0766 - val_accuracy: 0.9030 - val_loss: 0.3550\n",
      "Epoch 14/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9728 - loss: 0.0671 - val_accuracy: 0.8987 - val_loss: 0.3817\n",
      "Epoch 15/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9711 - loss: 0.0638 - val_accuracy: 0.9090 - val_loss: 0.4153\n",
      "Epoch 16/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9764 - loss: 0.0595 - val_accuracy: 0.9142 - val_loss: 0.4802\n",
      "Epoch 17/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9757 - loss: 0.0605 - val_accuracy: 0.9099 - val_loss: 0.4902\n",
      "Epoch 18/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9833 - loss: 0.0456 - val_accuracy: 0.8987 - val_loss: 0.4417\n",
      "Epoch 19/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9816 - loss: 0.0488 - val_accuracy: 0.9193 - val_loss: 0.5059\n",
      "Epoch 20/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9815 - loss: 0.0460 - val_accuracy: 0.9047 - val_loss: 0.4807\n",
      "Epoch 21/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9835 - loss: 0.0415 - val_accuracy: 0.9030 - val_loss: 0.5126\n",
      "Epoch 22/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9777 - loss: 0.0507 - val_accuracy: 0.9064 - val_loss: 0.5073\n",
      "Epoch 23/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9772 - loss: 0.0503 - val_accuracy: 0.8996 - val_loss: 0.5184\n",
      "Epoch 24/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9872 - loss: 0.0370 - val_accuracy: 0.9073 - val_loss: 0.4894\n",
      "Epoch 25/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9828 - loss: 0.0388 - val_accuracy: 0.9056 - val_loss: 0.5411\n",
      "Epoch 26/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9824 - loss: 0.0384 - val_accuracy: 0.9030 - val_loss: 0.5322\n",
      "Epoch 27/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9784 - loss: 0.0429 - val_accuracy: 0.8996 - val_loss: 0.5788\n",
      "Epoch 28/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9821 - loss: 0.0420 - val_accuracy: 0.9090 - val_loss: 0.5945\n",
      "Epoch 29/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9787 - loss: 0.0406 - val_accuracy: 0.9073 - val_loss: 0.6426\n",
      "Epoch 30/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9816 - loss: 0.0362 - val_accuracy: 0.9047 - val_loss: 0.5878\n",
      "Epoch 31/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9862 - loss: 0.0301 - val_accuracy: 0.9004 - val_loss: 0.6045\n",
      "Epoch 32/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9810 - loss: 0.0376 - val_accuracy: 0.9004 - val_loss: 0.6039\n",
      "Epoch 33/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9823 - loss: 0.0340 - val_accuracy: 0.9013 - val_loss: 0.6205\n",
      "Epoch 34/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9813 - loss: 0.0397 - val_accuracy: 0.9030 - val_loss: 0.5666\n",
      "Epoch 35/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9825 - loss: 0.0354 - val_accuracy: 0.8876 - val_loss: 0.6022\n",
      "Epoch 36/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9800 - loss: 0.0523 - val_accuracy: 0.8987 - val_loss: 0.5534\n",
      "Epoch 37/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9830 - loss: 0.0387 - val_accuracy: 0.9099 - val_loss: 0.6294\n",
      "Epoch 38/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9776 - loss: 0.0562 - val_accuracy: 0.9047 - val_loss: 0.6318\n",
      "Epoch 39/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9840 - loss: 0.0331 - val_accuracy: 0.9021 - val_loss: 0.6235\n",
      "Epoch 40/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9801 - loss: 0.0326 - val_accuracy: 0.8970 - val_loss: 0.6431\n",
      "Epoch 41/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9869 - loss: 0.0251 - val_accuracy: 0.9021 - val_loss: 0.6512\n",
      "Epoch 42/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9870 - loss: 0.0260 - val_accuracy: 0.9030 - val_loss: 0.6511\n",
      "Epoch 43/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9827 - loss: 0.0305 - val_accuracy: 0.9073 - val_loss: 0.6884\n",
      "Epoch 44/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9838 - loss: 0.0301 - val_accuracy: 0.9064 - val_loss: 0.6895\n",
      "Epoch 45/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9854 - loss: 0.0281 - val_accuracy: 0.9090 - val_loss: 0.6902\n",
      "Epoch 46/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9826 - loss: 0.0299 - val_accuracy: 0.9039 - val_loss: 0.6783\n",
      "Epoch 47/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9836 - loss: 0.0306 - val_accuracy: 0.9021 - val_loss: 0.7015\n",
      "Epoch 48/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9867 - loss: 0.0300 - val_accuracy: 0.8996 - val_loss: 0.6930\n",
      "Epoch 49/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9795 - loss: 0.0349 - val_accuracy: 0.9004 - val_loss: 0.7349\n",
      "Epoch 50/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9823 - loss: 0.0319 - val_accuracy: 0.9073 - val_loss: 0.6952\n",
      "Epoch 51/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9831 - loss: 0.0314 - val_accuracy: 0.8996 - val_loss: 0.6954\n",
      "Epoch 52/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9875 - loss: 0.0276 - val_accuracy: 0.8961 - val_loss: 0.6724\n",
      "Epoch 53/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9844 - loss: 0.0275 - val_accuracy: 0.9099 - val_loss: 0.7446\n",
      "Epoch 54/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9832 - loss: 0.0305 - val_accuracy: 0.8996 - val_loss: 0.6977\n",
      "Epoch 55/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9888 - loss: 0.0229 - val_accuracy: 0.9133 - val_loss: 0.7729\n",
      "Epoch 56/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9850 - loss: 0.0271 - val_accuracy: 0.9090 - val_loss: 0.7641\n",
      "Epoch 57/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9822 - loss: 0.0305 - val_accuracy: 0.9107 - val_loss: 0.8451\n",
      "Epoch 58/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9822 - loss: 0.0317 - val_accuracy: 0.9021 - val_loss: 0.7266\n",
      "Epoch 59/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9842 - loss: 0.0316 - val_accuracy: 0.9142 - val_loss: 0.7962\n",
      "Epoch 60/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.9843 - loss: 0.0353 - val_accuracy: 0.9056 - val_loss: 0.6920\n",
      "Epoch 61/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9820 - loss: 0.0380 - val_accuracy: 0.9064 - val_loss: 0.7785\n",
      "Epoch 62/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9850 - loss: 0.0351 - val_accuracy: 0.9013 - val_loss: 0.7677\n",
      "Epoch 63/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9844 - loss: 0.0273 - val_accuracy: 0.9013 - val_loss: 0.7751\n",
      "Epoch 64/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9816 - loss: 0.0306 - val_accuracy: 0.9082 - val_loss: 0.8321\n",
      "Epoch 65/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9861 - loss: 0.0265 - val_accuracy: 0.9082 - val_loss: 0.7945\n",
      "Epoch 66/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9877 - loss: 0.0241 - val_accuracy: 0.9056 - val_loss: 0.8546\n",
      "Epoch 67/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9873 - loss: 0.0224 - val_accuracy: 0.9064 - val_loss: 0.8248\n",
      "Epoch 68/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9873 - loss: 0.0222 - val_accuracy: 0.9030 - val_loss: 0.8254\n",
      "Epoch 69/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9867 - loss: 0.0226 - val_accuracy: 0.9064 - val_loss: 0.8241\n",
      "Epoch 70/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9857 - loss: 0.0278 - val_accuracy: 0.9030 - val_loss: 0.8042\n",
      "Epoch 71/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9862 - loss: 0.0247 - val_accuracy: 0.9064 - val_loss: 0.7891\n",
      "Epoch 72/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9894 - loss: 0.0235 - val_accuracy: 0.8936 - val_loss: 0.8093\n",
      "Epoch 73/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9876 - loss: 0.0246 - val_accuracy: 0.9056 - val_loss: 0.8132\n",
      "Epoch 74/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9835 - loss: 0.0259 - val_accuracy: 0.9133 - val_loss: 0.8418\n",
      "Epoch 75/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9890 - loss: 0.0243 - val_accuracy: 0.8927 - val_loss: 0.8557\n",
      "Epoch 76/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9888 - loss: 0.0216 - val_accuracy: 0.8961 - val_loss: 0.8178\n",
      "Epoch 77/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9851 - loss: 0.0274 - val_accuracy: 0.8987 - val_loss: 0.7441\n",
      "Epoch 78/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9784 - loss: 0.0385 - val_accuracy: 0.9082 - val_loss: 0.8048\n",
      "Epoch 79/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9845 - loss: 0.0315 - val_accuracy: 0.9099 - val_loss: 0.8100\n",
      "Epoch 80/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9854 - loss: 0.0295 - val_accuracy: 0.9107 - val_loss: 0.9344\n",
      "Epoch 81/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9850 - loss: 0.0303 - val_accuracy: 0.9142 - val_loss: 0.7994\n",
      "Epoch 82/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9867 - loss: 0.0279 - val_accuracy: 0.9064 - val_loss: 0.7679\n",
      "Epoch 83/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9869 - loss: 0.0261 - val_accuracy: 0.9064 - val_loss: 0.8810\n",
      "Epoch 84/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9872 - loss: 0.0214 - val_accuracy: 0.9013 - val_loss: 0.8609\n",
      "Epoch 85/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9929 - loss: 0.0174 - val_accuracy: 0.9039 - val_loss: 0.8821\n",
      "Epoch 86/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9879 - loss: 0.0212 - val_accuracy: 0.9056 - val_loss: 0.9454\n",
      "Epoch 87/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9872 - loss: 0.0216 - val_accuracy: 0.9047 - val_loss: 0.9328\n",
      "Epoch 88/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9880 - loss: 0.0190 - val_accuracy: 0.9056 - val_loss: 0.9544\n",
      "Epoch 89/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9884 - loss: 0.0192 - val_accuracy: 0.9099 - val_loss: 0.9899\n",
      "Epoch 90/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9880 - loss: 0.0221 - val_accuracy: 0.9073 - val_loss: 1.0398\n",
      "Epoch 91/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9882 - loss: 0.0193 - val_accuracy: 0.9064 - val_loss: 0.9549\n",
      "Epoch 92/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9868 - loss: 0.0195 - val_accuracy: 0.9099 - val_loss: 0.9635\n",
      "Epoch 93/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9872 - loss: 0.0213 - val_accuracy: 0.9107 - val_loss: 0.9353\n",
      "Epoch 94/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9878 - loss: 0.0228 - val_accuracy: 0.9073 - val_loss: 0.9582\n",
      "Epoch 95/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9845 - loss: 0.0245 - val_accuracy: 0.9073 - val_loss: 0.9576\n",
      "Epoch 96/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.9903 - loss: 0.0202 - val_accuracy: 0.9090 - val_loss: 0.9772\n",
      "Epoch 97/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9894 - loss: 0.0217 - val_accuracy: 0.8936 - val_loss: 0.9284\n",
      "Epoch 98/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9854 - loss: 0.0288 - val_accuracy: 0.9124 - val_loss: 1.0109\n",
      "Epoch 99/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9862 - loss: 0.0259 - val_accuracy: 0.9013 - val_loss: 0.9547\n",
      "Epoch 100/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9878 - loss: 0.0218 - val_accuracy: 0.9064 - val_loss: 1.0163\n",
      "Epoch 101/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9870 - loss: 0.0235 - val_accuracy: 0.9099 - val_loss: 1.0481\n",
      "Epoch 102/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9843 - loss: 0.0329 - val_accuracy: 0.8893 - val_loss: 0.8531\n",
      "Epoch 103/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9809 - loss: 0.0612 - val_accuracy: 0.9039 - val_loss: 0.8316\n",
      "Epoch 104/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9831 - loss: 0.0398 - val_accuracy: 0.9133 - val_loss: 0.7991\n",
      "Epoch 105/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9886 - loss: 0.0225 - val_accuracy: 0.9116 - val_loss: 0.9112\n",
      "Epoch 106/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9859 - loss: 0.0262 - val_accuracy: 0.9099 - val_loss: 0.9245\n",
      "Epoch 107/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9894 - loss: 0.0193 - val_accuracy: 0.9039 - val_loss: 0.9360\n",
      "Epoch 108/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9908 - loss: 0.0174 - val_accuracy: 0.9039 - val_loss: 0.9726\n",
      "Epoch 109/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9907 - loss: 0.0190 - val_accuracy: 0.9021 - val_loss: 0.9735\n",
      "Epoch 110/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.9869 - loss: 0.0205 - val_accuracy: 0.9056 - val_loss: 0.9752\n",
      "Epoch 111/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9866 - loss: 0.0222 - val_accuracy: 0.9013 - val_loss: 0.9208\n",
      "Epoch 112/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9887 - loss: 0.0187 - val_accuracy: 0.9030 - val_loss: 0.9511\n",
      "Epoch 113/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9885 - loss: 0.0196 - val_accuracy: 0.9004 - val_loss: 0.9389\n",
      "Epoch 114/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9873 - loss: 0.0207 - val_accuracy: 0.9073 - val_loss: 1.0431\n",
      "Epoch 115/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9906 - loss: 0.0181 - val_accuracy: 0.9021 - val_loss: 0.9755\n",
      "Epoch 116/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9890 - loss: 0.0184 - val_accuracy: 0.9073 - val_loss: 0.9886\n",
      "Epoch 117/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9874 - loss: 0.0221 - val_accuracy: 0.9064 - val_loss: 0.9217\n",
      "Epoch 118/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9869 - loss: 0.0275 - val_accuracy: 0.9064 - val_loss: 0.9551\n",
      "Epoch 119/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9870 - loss: 0.0262 - val_accuracy: 0.9013 - val_loss: 0.9308\n",
      "Epoch 120/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9874 - loss: 0.0263 - val_accuracy: 0.9107 - val_loss: 0.9632\n",
      "Epoch 121/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9905 - loss: 0.0183 - val_accuracy: 0.9073 - val_loss: 0.9384\n",
      "Epoch 122/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9881 - loss: 0.0195 - val_accuracy: 0.9064 - val_loss: 0.9891\n",
      "Epoch 123/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9901 - loss: 0.0167 - val_accuracy: 0.9030 - val_loss: 1.0058\n",
      "Epoch 124/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9884 - loss: 0.0197 - val_accuracy: 0.9082 - val_loss: 0.9863\n",
      "Epoch 125/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9931 - loss: 0.0152 - val_accuracy: 0.9047 - val_loss: 1.0275\n",
      "Epoch 126/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9899 - loss: 0.0184 - val_accuracy: 0.9021 - val_loss: 1.0303\n",
      "Epoch 127/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9881 - loss: 0.0203 - val_accuracy: 0.9090 - val_loss: 1.0688\n",
      "Epoch 128/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9897 - loss: 0.0165 - val_accuracy: 0.9064 - val_loss: 1.0630\n",
      "Epoch 129/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9897 - loss: 0.0181 - val_accuracy: 0.9073 - val_loss: 0.9725\n",
      "Epoch 130/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9886 - loss: 0.0235 - val_accuracy: 0.9082 - val_loss: 1.0530\n",
      "Epoch 131/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9791 - loss: 0.0448 - val_accuracy: 0.9099 - val_loss: 0.8967\n",
      "Epoch 132/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9882 - loss: 0.0254 - val_accuracy: 0.9073 - val_loss: 0.9400\n",
      "Epoch 133/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9859 - loss: 0.0229 - val_accuracy: 0.9082 - val_loss: 1.0031\n",
      "Epoch 134/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9888 - loss: 0.0235 - val_accuracy: 0.9004 - val_loss: 1.0246\n",
      "Epoch 135/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9875 - loss: 0.0206 - val_accuracy: 0.9082 - val_loss: 1.0946\n",
      "Epoch 136/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9876 - loss: 0.0181 - val_accuracy: 0.9064 - val_loss: 1.0830\n",
      "Epoch 137/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9901 - loss: 0.0160 - val_accuracy: 0.9056 - val_loss: 1.1584\n",
      "Epoch 138/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9889 - loss: 0.0167 - val_accuracy: 0.9064 - val_loss: 1.0616\n",
      "Epoch 139/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9878 - loss: 0.0179 - val_accuracy: 0.9056 - val_loss: 1.1139\n",
      "Epoch 140/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9900 - loss: 0.0190 - val_accuracy: 0.9039 - val_loss: 1.1265\n",
      "Epoch 141/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9884 - loss: 0.0202 - val_accuracy: 0.9099 - val_loss: 1.1238\n",
      "Epoch 142/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.9894 - loss: 0.0188 - val_accuracy: 0.9030 - val_loss: 1.0849\n",
      "Epoch 143/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9914 - loss: 0.0159 - val_accuracy: 0.9107 - val_loss: 1.1376\n",
      "Epoch 144/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9871 - loss: 0.0189 - val_accuracy: 0.9030 - val_loss: 1.0985\n",
      "Epoch 145/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9900 - loss: 0.0174 - val_accuracy: 0.9090 - val_loss: 1.1497\n",
      "Epoch 146/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9890 - loss: 0.0192 - val_accuracy: 0.9073 - val_loss: 1.1925\n",
      "Epoch 147/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9908 - loss: 0.0179 - val_accuracy: 0.9004 - val_loss: 1.0842\n",
      "Epoch 148/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9882 - loss: 0.0274 - val_accuracy: 0.9082 - val_loss: 0.9389\n",
      "Epoch 149/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9894 - loss: 0.0284 - val_accuracy: 0.9013 - val_loss: 0.9963\n",
      "Epoch 150/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9873 - loss: 0.0280 - val_accuracy: 0.9021 - val_loss: 1.0849\n",
      "Epoch 151/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.9887 - loss: 0.0187 - val_accuracy: 0.9099 - val_loss: 1.1760\n",
      "Epoch 152/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9912 - loss: 0.0158 - val_accuracy: 0.9064 - val_loss: 1.1183\n",
      "Epoch 153/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9935 - loss: 0.0141 - val_accuracy: 0.9047 - val_loss: 1.1403\n",
      "Epoch 154/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9894 - loss: 0.0172 - val_accuracy: 0.9013 - val_loss: 1.0895\n",
      "Epoch 155/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9874 - loss: 0.0233 - val_accuracy: 0.9039 - val_loss: 1.1015\n",
      "Epoch 156/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9891 - loss: 0.0169 - val_accuracy: 0.9099 - val_loss: 1.2220\n",
      "Epoch 157/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9908 - loss: 0.0175 - val_accuracy: 0.9030 - val_loss: 1.1011\n",
      "Epoch 158/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9911 - loss: 0.0157 - val_accuracy: 0.9039 - val_loss: 1.1015\n",
      "Epoch 159/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.9884 - loss: 0.0216 - val_accuracy: 0.9107 - val_loss: 1.2014\n",
      "Epoch 160/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9905 - loss: 0.0167 - val_accuracy: 0.9064 - val_loss: 1.1900\n",
      "Epoch 161/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.9909 - loss: 0.0162 - val_accuracy: 0.9039 - val_loss: 1.0520\n",
      "Epoch 162/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9882 - loss: 0.0195 - val_accuracy: 0.9021 - val_loss: 1.0931\n",
      "Epoch 163/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9879 - loss: 0.0208 - val_accuracy: 0.9047 - val_loss: 1.1482\n",
      "Epoch 164/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9898 - loss: 0.0243 - val_accuracy: 0.9047 - val_loss: 1.1422\n",
      "Epoch 165/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9874 - loss: 0.0236 - val_accuracy: 0.9133 - val_loss: 1.0890\n",
      "Epoch 166/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9841 - loss: 0.0420 - val_accuracy: 0.9116 - val_loss: 0.9176\n",
      "Epoch 167/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9854 - loss: 0.0282 - val_accuracy: 0.9124 - val_loss: 0.9724\n",
      "Epoch 168/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.9868 - loss: 0.0354 - val_accuracy: 0.9064 - val_loss: 0.9423\n",
      "Epoch 169/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9898 - loss: 0.0186 - val_accuracy: 0.9047 - val_loss: 1.0279\n",
      "Epoch 170/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9914 - loss: 0.0183 - val_accuracy: 0.8996 - val_loss: 0.9907\n",
      "Epoch 171/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9898 - loss: 0.0159 - val_accuracy: 0.9073 - val_loss: 1.0768\n",
      "Epoch 172/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9916 - loss: 0.0133 - val_accuracy: 0.9073 - val_loss: 1.0894\n",
      "Epoch 173/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9893 - loss: 0.0171 - val_accuracy: 0.9039 - val_loss: 1.1195\n",
      "Epoch 174/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9911 - loss: 0.0150 - val_accuracy: 0.9013 - val_loss: 1.0874\n",
      "Epoch 175/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9909 - loss: 0.0143 - val_accuracy: 0.9047 - val_loss: 1.1790\n",
      "Epoch 176/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9916 - loss: 0.0134 - val_accuracy: 0.9047 - val_loss: 1.1491\n",
      "Epoch 177/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9915 - loss: 0.0152 - val_accuracy: 0.9064 - val_loss: 1.1802\n",
      "Epoch 178/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9923 - loss: 0.0155 - val_accuracy: 0.9064 - val_loss: 1.0938\n",
      "Epoch 179/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9888 - loss: 0.0167 - val_accuracy: 0.9090 - val_loss: 1.1566\n",
      "Epoch 180/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9908 - loss: 0.0196 - val_accuracy: 0.8987 - val_loss: 1.0750\n",
      "Epoch 181/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9902 - loss: 0.0154 - val_accuracy: 0.9047 - val_loss: 1.0976\n",
      "Epoch 182/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9882 - loss: 0.0191 - val_accuracy: 0.9047 - val_loss: 1.1474\n",
      "Epoch 183/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9922 - loss: 0.0151 - val_accuracy: 0.9004 - val_loss: 1.1227\n",
      "Epoch 184/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9903 - loss: 0.0159 - val_accuracy: 0.9107 - val_loss: 1.2465\n",
      "Epoch 185/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9875 - loss: 0.0209 - val_accuracy: 0.9047 - val_loss: 1.1573\n",
      "Epoch 186/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9920 - loss: 0.0152 - val_accuracy: 0.9099 - val_loss: 1.2230\n",
      "Epoch 187/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9924 - loss: 0.0172 - val_accuracy: 0.9030 - val_loss: 1.2138\n",
      "Epoch 188/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9905 - loss: 0.0159 - val_accuracy: 0.9124 - val_loss: 1.2607\n",
      "Epoch 189/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9879 - loss: 0.0194 - val_accuracy: 0.9030 - val_loss: 1.1661\n",
      "Epoch 190/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9896 - loss: 0.0182 - val_accuracy: 0.9064 - val_loss: 1.1996\n",
      "Epoch 191/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9891 - loss: 0.0192 - val_accuracy: 0.9013 - val_loss: 1.0935\n",
      "Epoch 192/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.9893 - loss: 0.0215 - val_accuracy: 0.9142 - val_loss: 1.1697\n",
      "Epoch 193/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9884 - loss: 0.0344 - val_accuracy: 0.8979 - val_loss: 0.9854\n",
      "Epoch 194/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9867 - loss: 0.0338 - val_accuracy: 0.9150 - val_loss: 0.9302\n",
      "Epoch 195/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9858 - loss: 0.0312 - val_accuracy: 0.9167 - val_loss: 1.0413\n",
      "Epoch 196/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9903 - loss: 0.0215 - val_accuracy: 0.9082 - val_loss: 0.9239\n",
      "Epoch 197/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9882 - loss: 0.0212 - val_accuracy: 0.9073 - val_loss: 1.0183\n",
      "Epoch 198/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9919 - loss: 0.0141 - val_accuracy: 0.9090 - val_loss: 1.0244\n",
      "Epoch 199/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9908 - loss: 0.0171 - val_accuracy: 0.9142 - val_loss: 1.1189\n",
      "Epoch 200/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9921 - loss: 0.0145 - val_accuracy: 0.9056 - val_loss: 1.0940\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=200, \n",
    "                    batch_size=32, \n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e76b4ffe-ad75-4e50-a12d-6601b8cf89d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,133</span> (250.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m64,133\u001b[0m (250.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,377</span> (83.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,377\u001b[0m (83.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,756</span> (167.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m42,756\u001b[0m (167.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c06cedf7-c968-4f06-91a2-5339606eefac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 0.9050 - loss: 1.0117\n",
      "Test Accuracy: 0.9056\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_valid, y_valid)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = (model.predict(X_valid) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5e80c-d705-4b01-9efc-5d5416335bb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Build the DNN Model using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db5d7edd-217f-4370-9ffd-13b9e556f806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input layer\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# First hidden layer\n",
    "x = Dense(128, activation='relu')(inputs)\n",
    "\n",
    "# Second hidden layer\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# Third hidden layer\n",
    "x = Dense(32, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d1810d6-3e4a-420e-9a82-dbecdc3c286d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Output layer (sigmoid for binary classification)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model_2 = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a142cb2-97b6-461a-97af-ddd64eb5de28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_2.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a223b886-922b-4811-8e72-696679b2a80d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,377</span> (83.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,377\u001b[0m (83.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,377</span> (83.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,377\u001b[0m (83.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95e39b3e-b1e8-4eca-948c-d0ab21f51ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.8663 - loss: 0.3393 - val_accuracy: 0.9305 - val_loss: 0.2427\n",
      "Epoch 2/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9404 - loss: 0.2006 - val_accuracy: 0.9305 - val_loss: 0.2427\n",
      "Epoch 3/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9472 - loss: 0.1679 - val_accuracy: 0.9296 - val_loss: 0.2362\n",
      "Epoch 4/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9441 - loss: 0.1668 - val_accuracy: 0.9288 - val_loss: 0.2456\n",
      "Epoch 5/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9469 - loss: 0.1571 - val_accuracy: 0.9262 - val_loss: 0.2483\n",
      "Epoch 6/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9476 - loss: 0.1503 - val_accuracy: 0.9288 - val_loss: 0.2586\n",
      "Epoch 7/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9552 - loss: 0.1216 - val_accuracy: 0.9279 - val_loss: 0.2578\n",
      "Epoch 8/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9550 - loss: 0.1221 - val_accuracy: 0.9227 - val_loss: 0.2846\n",
      "Epoch 9/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9579 - loss: 0.1088 - val_accuracy: 0.9210 - val_loss: 0.3016\n",
      "Epoch 10/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9621 - loss: 0.0992 - val_accuracy: 0.9150 - val_loss: 0.3045\n",
      "Epoch 11/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9671 - loss: 0.0906 - val_accuracy: 0.9107 - val_loss: 0.3188\n",
      "Epoch 12/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9703 - loss: 0.0783 - val_accuracy: 0.9030 - val_loss: 0.3258\n",
      "Epoch 13/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9644 - loss: 0.0870 - val_accuracy: 0.9124 - val_loss: 0.4005\n",
      "Epoch 14/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.9687 - loss: 0.0733 - val_accuracy: 0.9167 - val_loss: 0.3957\n",
      "Epoch 15/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9714 - loss: 0.0671 - val_accuracy: 0.9116 - val_loss: 0.4384\n",
      "Epoch 16/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9724 - loss: 0.0610 - val_accuracy: 0.9013 - val_loss: 0.4342\n",
      "Epoch 17/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9793 - loss: 0.0552 - val_accuracy: 0.8944 - val_loss: 0.4393\n",
      "Epoch 18/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9764 - loss: 0.0540 - val_accuracy: 0.9124 - val_loss: 0.4619\n",
      "Epoch 19/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9807 - loss: 0.0496 - val_accuracy: 0.9056 - val_loss: 0.4641\n",
      "Epoch 20/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9757 - loss: 0.0505 - val_accuracy: 0.9099 - val_loss: 0.4599\n",
      "Epoch 21/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9814 - loss: 0.0423 - val_accuracy: 0.9073 - val_loss: 0.5269\n",
      "Epoch 22/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9809 - loss: 0.0455 - val_accuracy: 0.9107 - val_loss: 0.5727\n",
      "Epoch 23/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9804 - loss: 0.0419 - val_accuracy: 0.9167 - val_loss: 0.5973\n",
      "Epoch 24/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9800 - loss: 0.0420 - val_accuracy: 0.9193 - val_loss: 0.5670\n",
      "Epoch 25/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9762 - loss: 0.0472 - val_accuracy: 0.9073 - val_loss: 0.5326\n",
      "Epoch 26/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9852 - loss: 0.0329 - val_accuracy: 0.9099 - val_loss: 0.5676\n",
      "Epoch 27/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9827 - loss: 0.0422 - val_accuracy: 0.8979 - val_loss: 0.5464\n",
      "Epoch 28/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9836 - loss: 0.0427 - val_accuracy: 0.9013 - val_loss: 0.5486\n",
      "Epoch 29/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9749 - loss: 0.0552 - val_accuracy: 0.9159 - val_loss: 0.5941\n",
      "Epoch 30/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9825 - loss: 0.0364 - val_accuracy: 0.9124 - val_loss: 0.5659\n",
      "Epoch 31/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9872 - loss: 0.0375 - val_accuracy: 0.9159 - val_loss: 0.6143\n",
      "Epoch 32/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9796 - loss: 0.0622 - val_accuracy: 0.9047 - val_loss: 0.5885\n",
      "Epoch 33/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9836 - loss: 0.0326 - val_accuracy: 0.9082 - val_loss: 0.5605\n",
      "Epoch 34/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9851 - loss: 0.0315 - val_accuracy: 0.9107 - val_loss: 0.5722\n",
      "Epoch 35/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9857 - loss: 0.0313 - val_accuracy: 0.9133 - val_loss: 0.5926\n",
      "Epoch 36/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9865 - loss: 0.0323 - val_accuracy: 0.9073 - val_loss: 0.6418\n",
      "Epoch 37/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9833 - loss: 0.0344 - val_accuracy: 0.9167 - val_loss: 0.6568\n",
      "Epoch 38/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9847 - loss: 0.0318 - val_accuracy: 0.9082 - val_loss: 0.6583\n",
      "Epoch 39/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9841 - loss: 0.0329 - val_accuracy: 0.9047 - val_loss: 0.6422\n",
      "Epoch 40/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9835 - loss: 0.0305 - val_accuracy: 0.9116 - val_loss: 0.5934\n",
      "Epoch 41/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9852 - loss: 0.0288 - val_accuracy: 0.9064 - val_loss: 0.6248\n",
      "Epoch 42/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9834 - loss: 0.0320 - val_accuracy: 0.9150 - val_loss: 0.6567\n",
      "Epoch 43/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9816 - loss: 0.0316 - val_accuracy: 0.9116 - val_loss: 0.6973\n",
      "Epoch 44/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9846 - loss: 0.0320 - val_accuracy: 0.9150 - val_loss: 0.6837\n",
      "Epoch 45/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9857 - loss: 0.0268 - val_accuracy: 0.9133 - val_loss: 0.6875\n",
      "Epoch 46/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9830 - loss: 0.0301 - val_accuracy: 0.9013 - val_loss: 0.6499\n",
      "Epoch 47/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9882 - loss: 0.0246 - val_accuracy: 0.9082 - val_loss: 0.7092\n",
      "Epoch 48/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9850 - loss: 0.0312 - val_accuracy: 0.9099 - val_loss: 0.6676\n",
      "Epoch 49/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9867 - loss: 0.0287 - val_accuracy: 0.8961 - val_loss: 0.6302\n",
      "Epoch 50/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9846 - loss: 0.0368 - val_accuracy: 0.8884 - val_loss: 0.6033\n",
      "Epoch 51/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9841 - loss: 0.0301 - val_accuracy: 0.9099 - val_loss: 0.7115\n",
      "Epoch 52/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9812 - loss: 0.0335 - val_accuracy: 0.9013 - val_loss: 0.7042\n",
      "Epoch 53/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9839 - loss: 0.0293 - val_accuracy: 0.8996 - val_loss: 0.7264\n",
      "Epoch 54/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9816 - loss: 0.0374 - val_accuracy: 0.9107 - val_loss: 0.6989\n",
      "Epoch 55/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9831 - loss: 0.0315 - val_accuracy: 0.8987 - val_loss: 0.7322\n",
      "Epoch 56/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9842 - loss: 0.0284 - val_accuracy: 0.9056 - val_loss: 0.7083\n",
      "Epoch 57/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9884 - loss: 0.0230 - val_accuracy: 0.8970 - val_loss: 0.7631\n",
      "Epoch 58/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.9847 - loss: 0.0344 - val_accuracy: 0.9124 - val_loss: 0.7795\n",
      "Epoch 59/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9887 - loss: 0.0241 - val_accuracy: 0.9030 - val_loss: 0.7560\n",
      "Epoch 60/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9880 - loss: 0.0236 - val_accuracy: 0.9116 - val_loss: 0.8028\n",
      "Epoch 61/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9864 - loss: 0.0267 - val_accuracy: 0.8970 - val_loss: 0.7296\n",
      "Epoch 62/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9880 - loss: 0.0244 - val_accuracy: 0.8970 - val_loss: 0.7230\n",
      "Epoch 63/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9904 - loss: 0.0214 - val_accuracy: 0.9142 - val_loss: 0.8236\n",
      "Epoch 64/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9878 - loss: 0.0255 - val_accuracy: 0.9073 - val_loss: 0.8104\n",
      "Epoch 65/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9900 - loss: 0.0206 - val_accuracy: 0.8901 - val_loss: 0.7586\n",
      "Epoch 66/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9880 - loss: 0.0230 - val_accuracy: 0.8575 - val_loss: 0.7866\n",
      "Epoch 67/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9777 - loss: 0.0572 - val_accuracy: 0.9142 - val_loss: 0.7206\n",
      "Epoch 68/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9829 - loss: 0.0344 - val_accuracy: 0.8996 - val_loss: 0.7296\n",
      "Epoch 69/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9841 - loss: 0.0329 - val_accuracy: 0.8970 - val_loss: 0.7361\n",
      "Epoch 70/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9858 - loss: 0.0242 - val_accuracy: 0.9142 - val_loss: 0.8240\n",
      "Epoch 71/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9860 - loss: 0.0240 - val_accuracy: 0.9056 - val_loss: 0.7973\n",
      "Epoch 72/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9904 - loss: 0.0203 - val_accuracy: 0.9056 - val_loss: 0.7853\n",
      "Epoch 73/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9887 - loss: 0.0223 - val_accuracy: 0.9073 - val_loss: 0.7964\n",
      "Epoch 74/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9852 - loss: 0.0241 - val_accuracy: 0.9082 - val_loss: 0.8470\n",
      "Epoch 75/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9884 - loss: 0.0240 - val_accuracy: 0.9039 - val_loss: 0.7885\n",
      "Epoch 76/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9877 - loss: 0.0205 - val_accuracy: 0.9030 - val_loss: 0.8297\n",
      "Epoch 77/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9849 - loss: 0.0235 - val_accuracy: 0.8987 - val_loss: 0.7771\n",
      "Epoch 78/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9860 - loss: 0.0233 - val_accuracy: 0.9107 - val_loss: 0.8976\n",
      "Epoch 79/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9880 - loss: 0.0209 - val_accuracy: 0.9167 - val_loss: 0.9129\n",
      "Epoch 80/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9895 - loss: 0.0196 - val_accuracy: 0.8996 - val_loss: 0.8066\n",
      "Epoch 81/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9887 - loss: 0.0220 - val_accuracy: 0.9021 - val_loss: 0.8020\n",
      "Epoch 82/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9865 - loss: 0.0255 - val_accuracy: 0.9039 - val_loss: 0.8026\n",
      "Epoch 83/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9874 - loss: 0.0218 - val_accuracy: 0.9039 - val_loss: 0.8691\n",
      "Epoch 84/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9892 - loss: 0.0196 - val_accuracy: 0.9004 - val_loss: 0.8183\n",
      "Epoch 85/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9852 - loss: 0.0245 - val_accuracy: 0.9099 - val_loss: 0.8866\n",
      "Epoch 86/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9881 - loss: 0.0248 - val_accuracy: 0.9082 - val_loss: 0.8460\n",
      "Epoch 87/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.9837 - loss: 0.0325 - val_accuracy: 0.9082 - val_loss: 0.7883\n",
      "Epoch 88/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9882 - loss: 0.0275 - val_accuracy: 0.9004 - val_loss: 0.8031\n",
      "Epoch 89/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9904 - loss: 0.0198 - val_accuracy: 0.9047 - val_loss: 0.8701\n",
      "Epoch 90/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9874 - loss: 0.0230 - val_accuracy: 0.9133 - val_loss: 0.9386\n",
      "Epoch 91/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9869 - loss: 0.0260 - val_accuracy: 0.9030 - val_loss: 0.8161\n",
      "Epoch 92/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9890 - loss: 0.0186 - val_accuracy: 0.9021 - val_loss: 0.8615\n",
      "Epoch 93/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9904 - loss: 0.0192 - val_accuracy: 0.9090 - val_loss: 0.8692\n",
      "Epoch 94/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9864 - loss: 0.0240 - val_accuracy: 0.9064 - val_loss: 0.9434\n",
      "Epoch 95/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9871 - loss: 0.0245 - val_accuracy: 0.9099 - val_loss: 0.8242\n",
      "Epoch 96/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9863 - loss: 0.0285 - val_accuracy: 0.9013 - val_loss: 0.8433\n",
      "Epoch 97/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9873 - loss: 0.0215 - val_accuracy: 0.9073 - val_loss: 0.8729\n",
      "Epoch 98/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9893 - loss: 0.0182 - val_accuracy: 0.9090 - val_loss: 0.9726\n",
      "Epoch 99/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9869 - loss: 0.0236 - val_accuracy: 0.9064 - val_loss: 0.9136\n",
      "Epoch 100/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9908 - loss: 0.0159 - val_accuracy: 0.9013 - val_loss: 0.8794\n",
      "Epoch 101/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9899 - loss: 0.0184 - val_accuracy: 0.9116 - val_loss: 0.9301\n",
      "Epoch 102/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.9899 - loss: 0.0187 - val_accuracy: 0.9116 - val_loss: 1.0132\n",
      "Epoch 103/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9886 - loss: 0.0207 - val_accuracy: 0.9021 - val_loss: 0.8744\n",
      "Epoch 104/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9867 - loss: 0.0230 - val_accuracy: 0.9082 - val_loss: 0.9316\n",
      "Epoch 105/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9889 - loss: 0.0205 - val_accuracy: 0.9116 - val_loss: 1.0318\n",
      "Epoch 106/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9876 - loss: 0.0208 - val_accuracy: 0.9047 - val_loss: 1.0471\n",
      "Epoch 107/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9889 - loss: 0.0178 - val_accuracy: 0.8996 - val_loss: 1.0100\n",
      "Epoch 108/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9903 - loss: 0.0228 - val_accuracy: 0.9073 - val_loss: 0.8931\n",
      "Epoch 109/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9872 - loss: 0.0256 - val_accuracy: 0.9099 - val_loss: 0.8633\n",
      "Epoch 110/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9863 - loss: 0.0271 - val_accuracy: 0.8987 - val_loss: 0.9387\n",
      "Epoch 111/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9867 - loss: 0.0230 - val_accuracy: 0.9013 - val_loss: 0.9339\n",
      "Epoch 112/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9855 - loss: 0.0260 - val_accuracy: 0.9056 - val_loss: 1.0351\n",
      "Epoch 113/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9867 - loss: 0.0226 - val_accuracy: 0.9004 - val_loss: 0.9020\n",
      "Epoch 114/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9909 - loss: 0.0183 - val_accuracy: 0.9082 - val_loss: 0.9726\n",
      "Epoch 115/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9890 - loss: 0.0198 - val_accuracy: 0.9064 - val_loss: 0.9864\n",
      "Epoch 116/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.9907 - loss: 0.0165 - val_accuracy: 0.9107 - val_loss: 1.0211\n",
      "Epoch 117/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9877 - loss: 0.0213 - val_accuracy: 0.8979 - val_loss: 0.9772\n",
      "Epoch 118/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9890 - loss: 0.0206 - val_accuracy: 0.9047 - val_loss: 1.0042\n",
      "Epoch 119/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9858 - loss: 0.0245 - val_accuracy: 0.9073 - val_loss: 0.9794\n",
      "Epoch 120/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9889 - loss: 0.0217 - val_accuracy: 0.9150 - val_loss: 1.0267\n",
      "Epoch 121/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9832 - loss: 0.0336 - val_accuracy: 0.9082 - val_loss: 0.9359\n",
      "Epoch 122/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9876 - loss: 0.0249 - val_accuracy: 0.9056 - val_loss: 0.9538\n",
      "Epoch 123/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9902 - loss: 0.0208 - val_accuracy: 0.9039 - val_loss: 1.0055\n",
      "Epoch 124/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9842 - loss: 0.0238 - val_accuracy: 0.8987 - val_loss: 0.9369\n",
      "Epoch 125/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9863 - loss: 0.0293 - val_accuracy: 0.9116 - val_loss: 0.9469\n",
      "Epoch 126/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9883 - loss: 0.0372 - val_accuracy: 0.9107 - val_loss: 0.8359\n",
      "Epoch 127/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9891 - loss: 0.0205 - val_accuracy: 0.9082 - val_loss: 0.9296\n",
      "Epoch 128/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9905 - loss: 0.0155 - val_accuracy: 0.9073 - val_loss: 0.9350\n",
      "Epoch 129/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9887 - loss: 0.0171 - val_accuracy: 0.9090 - val_loss: 0.9908\n",
      "Epoch 130/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9868 - loss: 0.0179 - val_accuracy: 0.9090 - val_loss: 0.9958\n",
      "Epoch 131/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9903 - loss: 0.0157 - val_accuracy: 0.9073 - val_loss: 0.9987\n",
      "Epoch 132/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9890 - loss: 0.0205 - val_accuracy: 0.9013 - val_loss: 0.9433\n",
      "Epoch 133/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9907 - loss: 0.0182 - val_accuracy: 0.9056 - val_loss: 1.0159\n",
      "Epoch 134/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9924 - loss: 0.0165 - val_accuracy: 0.9073 - val_loss: 0.9916\n",
      "Epoch 135/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9871 - loss: 0.0185 - val_accuracy: 0.8953 - val_loss: 0.9698\n",
      "Epoch 136/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9911 - loss: 0.0191 - val_accuracy: 0.9021 - val_loss: 0.9371\n",
      "Epoch 137/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9887 - loss: 0.0200 - val_accuracy: 0.8996 - val_loss: 1.0007\n",
      "Epoch 138/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9900 - loss: 0.0174 - val_accuracy: 0.9056 - val_loss: 1.0149\n",
      "Epoch 139/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.9909 - loss: 0.0169 - val_accuracy: 0.9039 - val_loss: 1.0286\n",
      "Epoch 140/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9876 - loss: 0.0189 - val_accuracy: 0.9082 - val_loss: 1.0454\n",
      "Epoch 141/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9868 - loss: 0.0242 - val_accuracy: 0.9064 - val_loss: 0.9196\n",
      "Epoch 142/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9894 - loss: 0.0212 - val_accuracy: 0.9021 - val_loss: 0.9655\n",
      "Epoch 143/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9864 - loss: 0.0289 - val_accuracy: 0.9073 - val_loss: 0.8728\n",
      "Epoch 144/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9894 - loss: 0.0239 - val_accuracy: 0.9116 - val_loss: 0.9550\n",
      "Epoch 145/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9871 - loss: 0.0268 - val_accuracy: 0.9073 - val_loss: 0.9561\n",
      "Epoch 146/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9888 - loss: 0.0213 - val_accuracy: 0.9133 - val_loss: 1.0373\n",
      "Epoch 147/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9882 - loss: 0.0189 - val_accuracy: 0.9107 - val_loss: 1.0749\n",
      "Epoch 148/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9905 - loss: 0.0154 - val_accuracy: 0.9030 - val_loss: 1.0517\n",
      "Epoch 149/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9889 - loss: 0.0216 - val_accuracy: 0.9021 - val_loss: 0.9925\n",
      "Epoch 150/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9906 - loss: 0.0201 - val_accuracy: 0.9090 - val_loss: 1.0204\n",
      "Epoch 151/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9890 - loss: 0.0189 - val_accuracy: 0.9082 - val_loss: 1.0915\n",
      "Epoch 152/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9931 - loss: 0.0145 - val_accuracy: 0.9064 - val_loss: 1.1109\n",
      "Epoch 153/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9908 - loss: 0.0153 - val_accuracy: 0.9064 - val_loss: 1.0832\n",
      "Epoch 154/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9912 - loss: 0.0199 - val_accuracy: 0.9099 - val_loss: 1.0832\n",
      "Epoch 155/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9913 - loss: 0.0162 - val_accuracy: 0.9090 - val_loss: 1.0878\n",
      "Epoch 156/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9888 - loss: 0.0185 - val_accuracy: 0.9064 - val_loss: 1.1006\n",
      "Epoch 157/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9904 - loss: 0.0179 - val_accuracy: 0.9030 - val_loss: 1.0317\n",
      "Epoch 158/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.9896 - loss: 0.0151 - val_accuracy: 0.9099 - val_loss: 1.1502\n",
      "Epoch 159/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9900 - loss: 0.0172 - val_accuracy: 0.8979 - val_loss: 1.0450\n",
      "Epoch 160/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9898 - loss: 0.0173 - val_accuracy: 0.9039 - val_loss: 1.1205\n",
      "Epoch 161/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9910 - loss: 0.0166 - val_accuracy: 0.9056 - val_loss: 1.0947\n",
      "Epoch 162/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9897 - loss: 0.0184 - val_accuracy: 0.9021 - val_loss: 1.1148\n",
      "Epoch 163/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9883 - loss: 0.0229 - val_accuracy: 0.9064 - val_loss: 1.0448\n",
      "Epoch 164/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9833 - loss: 0.0479 - val_accuracy: 0.8944 - val_loss: 0.7742\n",
      "Epoch 165/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9831 - loss: 0.0417 - val_accuracy: 0.9116 - val_loss: 0.8438\n",
      "Epoch 166/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.9864 - loss: 0.0252 - val_accuracy: 0.9082 - val_loss: 0.8609\n",
      "Epoch 167/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9900 - loss: 0.0168 - val_accuracy: 0.9073 - val_loss: 0.9369\n",
      "Epoch 168/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9911 - loss: 0.0170 - val_accuracy: 0.9107 - val_loss: 1.0138\n",
      "Epoch 169/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9910 - loss: 0.0174 - val_accuracy: 0.9099 - val_loss: 1.0204\n",
      "Epoch 170/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9913 - loss: 0.0181 - val_accuracy: 0.9107 - val_loss: 1.0084\n",
      "Epoch 171/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9896 - loss: 0.0165 - val_accuracy: 0.9073 - val_loss: 1.0078\n",
      "Epoch 172/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9931 - loss: 0.0158 - val_accuracy: 0.9064 - val_loss: 1.0124\n",
      "Epoch 173/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9927 - loss: 0.0124 - val_accuracy: 0.9073 - val_loss: 1.0505\n",
      "Epoch 174/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9904 - loss: 0.0157 - val_accuracy: 0.9099 - val_loss: 1.0726\n",
      "Epoch 175/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.9925 - loss: 0.0151 - val_accuracy: 0.9099 - val_loss: 1.0369\n",
      "Epoch 176/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9904 - loss: 0.0157 - val_accuracy: 0.9116 - val_loss: 1.0875\n",
      "Epoch 177/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9907 - loss: 0.0166 - val_accuracy: 0.9090 - val_loss: 1.0935\n",
      "Epoch 178/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9907 - loss: 0.0174 - val_accuracy: 0.9039 - val_loss: 1.0406\n",
      "Epoch 179/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9919 - loss: 0.0149 - val_accuracy: 0.9124 - val_loss: 1.0835\n",
      "Epoch 180/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9882 - loss: 0.0283 - val_accuracy: 0.9030 - val_loss: 0.9886\n",
      "Epoch 181/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9863 - loss: 0.0281 - val_accuracy: 0.9039 - val_loss: 0.9507\n",
      "Epoch 182/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9900 - loss: 0.0322 - val_accuracy: 0.9159 - val_loss: 0.9591\n",
      "Epoch 183/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.9908 - loss: 0.0150 - val_accuracy: 0.9064 - val_loss: 0.9700\n",
      "Epoch 184/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9848 - loss: 0.1101 - val_accuracy: 0.9082 - val_loss: 0.8588\n",
      "Epoch 185/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9879 - loss: 0.0187 - val_accuracy: 0.9116 - val_loss: 0.8636\n",
      "Epoch 186/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9878 - loss: 0.0191 - val_accuracy: 0.9056 - val_loss: 0.8986\n",
      "Epoch 187/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9905 - loss: 0.0145 - val_accuracy: 0.9056 - val_loss: 0.9714\n",
      "Epoch 188/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9904 - loss: 0.0149 - val_accuracy: 0.9064 - val_loss: 0.9722\n",
      "Epoch 189/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9892 - loss: 0.0181 - val_accuracy: 0.9056 - val_loss: 1.0037\n",
      "Epoch 190/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9905 - loss: 0.0176 - val_accuracy: 0.9082 - val_loss: 0.9678\n",
      "Epoch 191/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.9904 - loss: 0.0154 - val_accuracy: 0.9133 - val_loss: 1.0333\n",
      "Epoch 192/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9903 - loss: 0.0166 - val_accuracy: 0.9116 - val_loss: 0.9893\n",
      "Epoch 193/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9896 - loss: 0.0170 - val_accuracy: 0.9082 - val_loss: 0.9052\n",
      "Epoch 194/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9896 - loss: 0.0191 - val_accuracy: 0.9064 - val_loss: 0.9278\n",
      "Epoch 195/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9890 - loss: 0.0165 - val_accuracy: 0.9073 - val_loss: 0.9796\n",
      "Epoch 196/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9911 - loss: 0.0154 - val_accuracy: 0.9107 - val_loss: 1.0285\n",
      "Epoch 197/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9910 - loss: 0.0140 - val_accuracy: 0.9082 - val_loss: 1.0220\n",
      "Epoch 198/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.9877 - loss: 0.0179 - val_accuracy: 0.9107 - val_loss: 1.0230\n",
      "Epoch 199/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9922 - loss: 0.0132 - val_accuracy: 0.9116 - val_loss: 1.0173\n",
      "Epoch 200/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9933 - loss: 0.0154 - val_accuracy: 0.9090 - val_loss: 0.9715\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.9075 - loss: 0.9794\n",
      "Test Accuracy: 0.9090\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model_2.fit(X_train, y_train, \n",
    "                    epochs=200, \n",
    "                    batch_size=32, \n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model_2.evaluate(X_valid, y_valid)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6ab481d-c5e5-4b4c-9963-0b3e49e97dca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = (model.predict(X_valid) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f38277-caed-4d97-b717-bbb413a33ebe",
   "metadata": {},
   "source": [
    "### Adding regularization to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3025f45b-b172-4ee0-aa29-bcbf3b666740",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - accuracy: 0.9333 - loss: 13.3945 - val_accuracy: 0.9305 - val_loss: 1.6418\n",
      "Epoch 2/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9350 - loss: 0.9252 - val_accuracy: 0.9305 - val_loss: 0.3637\n",
      "Epoch 3/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9403 - loss: 0.3184 - val_accuracy: 0.9305 - val_loss: 0.3114\n",
      "Epoch 4/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9409 - loss: 0.2744 - val_accuracy: 0.9305 - val_loss: 0.2921\n",
      "Epoch 5/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9431 - loss: 0.2522 - val_accuracy: 0.9305 - val_loss: 0.2852\n",
      "Epoch 6/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9413 - loss: 0.2506 - val_accuracy: 0.9305 - val_loss: 0.2808\n",
      "Epoch 7/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9437 - loss: 0.2411 - val_accuracy: 0.9305 - val_loss: 0.2813\n",
      "Epoch 8/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9452 - loss: 0.2369 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 9/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9391 - loss: 0.2538 - val_accuracy: 0.9305 - val_loss: 0.2821\n",
      "Epoch 10/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9440 - loss: 0.2400 - val_accuracy: 0.9305 - val_loss: 0.2810\n",
      "Epoch 11/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9398 - loss: 0.2517 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 12/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9465 - loss: 0.2330 - val_accuracy: 0.9305 - val_loss: 0.2807\n",
      "Epoch 13/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9470 - loss: 0.2321 - val_accuracy: 0.9305 - val_loss: 0.2814\n",
      "Epoch 14/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9433 - loss: 0.2422 - val_accuracy: 0.9305 - val_loss: 0.2824\n",
      "Epoch 15/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9481 - loss: 0.2288 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 16/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9431 - loss: 0.2427 - val_accuracy: 0.9305 - val_loss: 0.2816\n",
      "Epoch 17/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9397 - loss: 0.2524 - val_accuracy: 0.9305 - val_loss: 0.2829\n",
      "Epoch 18/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9425 - loss: 0.2443 - val_accuracy: 0.9305 - val_loss: 0.2819\n",
      "Epoch 19/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9452 - loss: 0.2367 - val_accuracy: 0.9305 - val_loss: 0.2814\n",
      "Epoch 20/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9418 - loss: 0.2463 - val_accuracy: 0.9305 - val_loss: 0.2824\n",
      "Epoch 21/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9472 - loss: 0.2313 - val_accuracy: 0.9305 - val_loss: 0.2819\n",
      "Epoch 22/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9426 - loss: 0.2444 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 23/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9391 - loss: 0.2540 - val_accuracy: 0.9305 - val_loss: 0.2821\n",
      "Epoch 24/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9454 - loss: 0.2361 - val_accuracy: 0.9305 - val_loss: 0.2821\n",
      "Epoch 25/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9439 - loss: 0.2409 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 26/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9400 - loss: 0.2515 - val_accuracy: 0.9305 - val_loss: 0.2824\n",
      "Epoch 27/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9439 - loss: 0.2406 - val_accuracy: 0.9305 - val_loss: 0.2819\n",
      "Epoch 28/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9421 - loss: 0.2456 - val_accuracy: 0.9305 - val_loss: 0.2824\n",
      "Epoch 29/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9371 - loss: 0.2594 - val_accuracy: 0.9305 - val_loss: 0.2839\n",
      "Epoch 30/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9460 - loss: 0.2347 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 31/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9448 - loss: 0.2379 - val_accuracy: 0.9305 - val_loss: 0.2811\n",
      "Epoch 32/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9381 - loss: 0.2565 - val_accuracy: 0.9305 - val_loss: 0.2826\n",
      "Epoch 33/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.9432 - loss: 0.2426 - val_accuracy: 0.9305 - val_loss: 0.2813\n",
      "Epoch 34/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9401 - loss: 0.2509 - val_accuracy: 0.9305 - val_loss: 0.2824\n",
      "Epoch 35/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9421 - loss: 0.2457 - val_accuracy: 0.9305 - val_loss: 0.2822\n",
      "Epoch 36/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9409 - loss: 0.2489 - val_accuracy: 0.9305 - val_loss: 0.2814\n",
      "Epoch 37/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9459 - loss: 0.2347 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 38/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9422 - loss: 0.2455 - val_accuracy: 0.9305 - val_loss: 0.2825\n",
      "Epoch 39/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9417 - loss: 0.2469 - val_accuracy: 0.9305 - val_loss: 0.2825\n",
      "Epoch 40/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9465 - loss: 0.2331 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 41/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9362 - loss: 0.2623 - val_accuracy: 0.9305 - val_loss: 0.2826\n",
      "Epoch 42/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9436 - loss: 0.2415 - val_accuracy: 0.9305 - val_loss: 0.2819\n",
      "Epoch 43/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9405 - loss: 0.2499 - val_accuracy: 0.9305 - val_loss: 0.2819\n",
      "Epoch 44/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9414 - loss: 0.2474 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 45/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9443 - loss: 0.2393 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 46/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9416 - loss: 0.2471 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 47/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9348 - loss: 0.2661 - val_accuracy: 0.9305 - val_loss: 0.2825\n",
      "Epoch 48/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9410 - loss: 0.2488 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 49/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9473 - loss: 0.2309 - val_accuracy: 0.9305 - val_loss: 0.2810\n",
      "Epoch 50/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9404 - loss: 0.2503 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 51/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9494 - loss: 0.2252 - val_accuracy: 0.9305 - val_loss: 0.2808\n",
      "Epoch 52/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9409 - loss: 0.2490 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 53/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.9494 - loss: 0.2252 - val_accuracy: 0.9305 - val_loss: 0.2810\n",
      "Epoch 54/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9372 - loss: 0.2591 - val_accuracy: 0.9305 - val_loss: 0.2823\n",
      "Epoch 55/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9365 - loss: 0.2614 - val_accuracy: 0.9305 - val_loss: 0.2824\n",
      "Epoch 56/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9382 - loss: 0.2567 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 57/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9427 - loss: 0.2438 - val_accuracy: 0.9305 - val_loss: 0.2819\n",
      "Epoch 58/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9385 - loss: 0.2558 - val_accuracy: 0.9305 - val_loss: 0.2825\n",
      "Epoch 59/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9398 - loss: 0.2524 - val_accuracy: 0.9305 - val_loss: 0.2822\n",
      "Epoch 60/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9379 - loss: 0.2572 - val_accuracy: 0.9305 - val_loss: 0.2831\n",
      "Epoch 61/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9418 - loss: 0.2469 - val_accuracy: 0.9305 - val_loss: 0.2821\n",
      "Epoch 62/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9482 - loss: 0.2282 - val_accuracy: 0.9305 - val_loss: 0.2810\n",
      "Epoch 63/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9453 - loss: 0.2370 - val_accuracy: 0.9305 - val_loss: 0.2812\n",
      "Epoch 64/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9441 - loss: 0.2401 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 65/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9428 - loss: 0.2437 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 66/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9411 - loss: 0.2484 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 67/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9463 - loss: 0.2339 - val_accuracy: 0.9305 - val_loss: 0.2811\n",
      "Epoch 68/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9419 - loss: 0.2461 - val_accuracy: 0.9305 - val_loss: 0.2821\n",
      "Epoch 69/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9429 - loss: 0.2432 - val_accuracy: 0.9305 - val_loss: 0.2827\n",
      "Epoch 70/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9452 - loss: 0.2368 - val_accuracy: 0.9305 - val_loss: 0.2819\n",
      "Epoch 71/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9445 - loss: 0.2388 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 72/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9440 - loss: 0.2403 - val_accuracy: 0.9305 - val_loss: 0.2812\n",
      "Epoch 73/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9458 - loss: 0.2353 - val_accuracy: 0.9305 - val_loss: 0.2814\n",
      "Epoch 74/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9392 - loss: 0.2536 - val_accuracy: 0.9305 - val_loss: 0.2830\n",
      "Epoch 75/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9382 - loss: 0.2570 - val_accuracy: 0.9305 - val_loss: 0.2829\n",
      "Epoch 76/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9444 - loss: 0.2391 - val_accuracy: 0.9305 - val_loss: 0.2808\n",
      "Epoch 77/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9451 - loss: 0.2373 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 78/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9382 - loss: 0.2565 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 79/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9423 - loss: 0.2452 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 80/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9415 - loss: 0.2472 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 81/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9430 - loss: 0.2430 - val_accuracy: 0.9305 - val_loss: 0.2811\n",
      "Epoch 82/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.9461 - loss: 0.2346 - val_accuracy: 0.9305 - val_loss: 0.2813\n",
      "Epoch 83/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9406 - loss: 0.2499 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 84/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9458 - loss: 0.2353 - val_accuracy: 0.9305 - val_loss: 0.2810\n",
      "Epoch 85/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9404 - loss: 0.2502 - val_accuracy: 0.9305 - val_loss: 0.2824\n",
      "Epoch 86/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9469 - loss: 0.2319 - val_accuracy: 0.9305 - val_loss: 0.2810\n",
      "Epoch 87/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9432 - loss: 0.2425 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 88/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9443 - loss: 0.2396 - val_accuracy: 0.9305 - val_loss: 0.2816\n",
      "Epoch 89/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9430 - loss: 0.2431 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 90/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9421 - loss: 0.2454 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 91/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9451 - loss: 0.2373 - val_accuracy: 0.9305 - val_loss: 0.2813\n",
      "Epoch 92/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9445 - loss: 0.2392 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 93/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9405 - loss: 0.2502 - val_accuracy: 0.9305 - val_loss: 0.2819\n",
      "Epoch 94/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9448 - loss: 0.2381 - val_accuracy: 0.9305 - val_loss: 0.2811\n",
      "Epoch 95/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9428 - loss: 0.2436 - val_accuracy: 0.9305 - val_loss: 0.2822\n",
      "Epoch 96/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9459 - loss: 0.2349 - val_accuracy: 0.9305 - val_loss: 0.2810\n",
      "Epoch 97/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9427 - loss: 0.2439 - val_accuracy: 0.9305 - val_loss: 0.2814\n",
      "Epoch 98/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.9437 - loss: 0.2411 - val_accuracy: 0.9305 - val_loss: 0.2826\n",
      "Epoch 99/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9459 - loss: 0.2350 - val_accuracy: 0.9305 - val_loss: 0.2819\n",
      "Epoch 100/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9440 - loss: 0.2404 - val_accuracy: 0.9305 - val_loss: 0.2812\n",
      "Epoch 101/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9439 - loss: 0.2406 - val_accuracy: 0.9305 - val_loss: 0.2816\n",
      "Epoch 102/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9440 - loss: 0.2405 - val_accuracy: 0.9305 - val_loss: 0.2821\n",
      "Epoch 103/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9419 - loss: 0.2464 - val_accuracy: 0.9305 - val_loss: 0.2819\n",
      "Epoch 104/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9386 - loss: 0.2555 - val_accuracy: 0.9305 - val_loss: 0.2833\n",
      "Epoch 105/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9491 - loss: 0.2263 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 106/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9447 - loss: 0.2383 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 107/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9409 - loss: 0.2490 - val_accuracy: 0.9305 - val_loss: 0.2814\n",
      "Epoch 108/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9399 - loss: 0.2520 - val_accuracy: 0.9305 - val_loss: 0.2822\n",
      "Epoch 109/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9407 - loss: 0.2497 - val_accuracy: 0.9305 - val_loss: 0.2809\n",
      "Epoch 110/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.9447 - loss: 0.2386 - val_accuracy: 0.9305 - val_loss: 0.2812\n",
      "Epoch 111/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9406 - loss: 0.2497 - val_accuracy: 0.9305 - val_loss: 0.2816\n",
      "Epoch 112/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9406 - loss: 0.2498 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 113/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9460 - loss: 0.2347 - val_accuracy: 0.9305 - val_loss: 0.2814\n",
      "Epoch 114/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9400 - loss: 0.2514 - val_accuracy: 0.9305 - val_loss: 0.2821\n",
      "Epoch 115/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9411 - loss: 0.2486 - val_accuracy: 0.9305 - val_loss: 0.2827\n",
      "Epoch 116/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9473 - loss: 0.2308 - val_accuracy: 0.9305 - val_loss: 0.2808\n",
      "Epoch 117/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9426 - loss: 0.2442 - val_accuracy: 0.9305 - val_loss: 0.2820\n",
      "Epoch 118/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9446 - loss: 0.2386 - val_accuracy: 0.9305 - val_loss: 0.2821\n",
      "Epoch 119/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9435 - loss: 0.2417 - val_accuracy: 0.9305 - val_loss: 0.2813\n",
      "Epoch 120/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9439 - loss: 0.2405 - val_accuracy: 0.9305 - val_loss: 0.2814\n",
      "Epoch 121/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9485 - loss: 0.2277 - val_accuracy: 0.9305 - val_loss: 0.2808\n",
      "Epoch 122/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9450 - loss: 0.2375 - val_accuracy: 0.9305 - val_loss: 0.2809\n",
      "Epoch 123/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9405 - loss: 0.2500 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 124/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9433 - loss: 0.2422 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 125/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9440 - loss: 0.2402 - val_accuracy: 0.9305 - val_loss: 0.2823\n",
      "Epoch 126/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9518 - loss: 0.2184 - val_accuracy: 0.9305 - val_loss: 0.2812\n",
      "Epoch 127/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9381 - loss: 0.2566 - val_accuracy: 0.9305 - val_loss: 0.2825\n",
      "Epoch 128/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9440 - loss: 0.2401 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 129/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9408 - loss: 0.2491 - val_accuracy: 0.9305 - val_loss: 0.2812\n",
      "Epoch 130/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9451 - loss: 0.2374 - val_accuracy: 0.9305 - val_loss: 0.2812\n",
      "Epoch 131/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9387 - loss: 0.2549 - val_accuracy: 0.9305 - val_loss: 0.2830\n",
      "Epoch 132/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9456 - loss: 0.2358 - val_accuracy: 0.9305 - val_loss: 0.2813\n",
      "Epoch 133/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9411 - loss: 0.2482 - val_accuracy: 0.9305 - val_loss: 0.2825\n",
      "Epoch 134/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.9444 - loss: 0.2389 - val_accuracy: 0.9305 - val_loss: 0.2821\n",
      "Epoch 135/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9438 - loss: 0.2406 - val_accuracy: 0.9305 - val_loss: 0.2819\n",
      "Epoch 136/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.9400 - loss: 0.2515 - val_accuracy: 0.9305 - val_loss: 0.2816\n",
      "Epoch 137/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9407 - loss: 0.2494 - val_accuracy: 0.9305 - val_loss: 0.2820\n",
      "Epoch 138/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9391 - loss: 0.2542 - val_accuracy: 0.9305 - val_loss: 0.2824\n",
      "Epoch 139/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9399 - loss: 0.2520 - val_accuracy: 0.9305 - val_loss: 0.2822\n",
      "Epoch 140/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9438 - loss: 0.2408 - val_accuracy: 0.9305 - val_loss: 0.2816\n",
      "Epoch 141/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9421 - loss: 0.2456 - val_accuracy: 0.9305 - val_loss: 0.2820\n",
      "Epoch 142/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9397 - loss: 0.2524 - val_accuracy: 0.9305 - val_loss: 0.2829\n",
      "Epoch 143/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9438 - loss: 0.2409 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 144/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9415 - loss: 0.2471 - val_accuracy: 0.9305 - val_loss: 0.2825\n",
      "Epoch 145/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.9442 - loss: 0.2398 - val_accuracy: 0.9305 - val_loss: 0.2814\n",
      "Epoch 146/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9443 - loss: 0.2396 - val_accuracy: 0.9305 - val_loss: 0.2812\n",
      "Epoch 147/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9413 - loss: 0.2477 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 148/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9446 - loss: 0.2385 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 149/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9461 - loss: 0.2343 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 150/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9396 - loss: 0.2524 - val_accuracy: 0.9305 - val_loss: 0.2829\n",
      "Epoch 151/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9410 - loss: 0.2491 - val_accuracy: 0.9305 - val_loss: 0.2822\n",
      "Epoch 152/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.9412 - loss: 0.2483 - val_accuracy: 0.9305 - val_loss: 0.2820\n",
      "Epoch 153/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9367 - loss: 0.2606 - val_accuracy: 0.9305 - val_loss: 0.2829\n",
      "Epoch 154/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9430 - loss: 0.2430 - val_accuracy: 0.9305 - val_loss: 0.2810\n",
      "Epoch 155/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9421 - loss: 0.2457 - val_accuracy: 0.9305 - val_loss: 0.2813\n",
      "Epoch 156/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9409 - loss: 0.2487 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 157/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9432 - loss: 0.2425 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 158/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9424 - loss: 0.2446 - val_accuracy: 0.9305 - val_loss: 0.2816\n",
      "Epoch 159/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9487 - loss: 0.2270 - val_accuracy: 0.9305 - val_loss: 0.2810\n",
      "Epoch 160/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9436 - loss: 0.2416 - val_accuracy: 0.9305 - val_loss: 0.2814\n",
      "Epoch 161/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9465 - loss: 0.2332 - val_accuracy: 0.9305 - val_loss: 0.2816\n",
      "Epoch 162/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9365 - loss: 0.2609 - val_accuracy: 0.9305 - val_loss: 0.2832\n",
      "Epoch 163/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9367 - loss: 0.2612 - val_accuracy: 0.9305 - val_loss: 0.2830\n",
      "Epoch 164/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.9401 - loss: 0.2516 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 165/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9445 - loss: 0.2388 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 166/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9438 - loss: 0.2409 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 167/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9424 - loss: 0.2448 - val_accuracy: 0.9305 - val_loss: 0.2816\n",
      "Epoch 168/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9404 - loss: 0.2502 - val_accuracy: 0.9305 - val_loss: 0.2822\n",
      "Epoch 169/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9370 - loss: 0.2599 - val_accuracy: 0.9305 - val_loss: 0.2823\n",
      "Epoch 170/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9399 - loss: 0.2517 - val_accuracy: 0.9305 - val_loss: 0.2829\n",
      "Epoch 171/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9471 - loss: 0.2312 - val_accuracy: 0.9305 - val_loss: 0.2809\n",
      "Epoch 172/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9429 - loss: 0.2433 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 173/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.9387 - loss: 0.2552 - val_accuracy: 0.9305 - val_loss: 0.2821\n",
      "Epoch 174/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9454 - loss: 0.2361 - val_accuracy: 0.9305 - val_loss: 0.2812\n",
      "Epoch 175/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9449 - loss: 0.2378 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 176/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9437 - loss: 0.2412 - val_accuracy: 0.9305 - val_loss: 0.2812\n",
      "Epoch 177/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9407 - loss: 0.2495 - val_accuracy: 0.9305 - val_loss: 0.2821\n",
      "Epoch 178/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9410 - loss: 0.2487 - val_accuracy: 0.9305 - val_loss: 0.2819\n",
      "Epoch 179/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9437 - loss: 0.2409 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 180/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9434 - loss: 0.2419 - val_accuracy: 0.9305 - val_loss: 0.2815\n",
      "Epoch 181/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9394 - loss: 0.2532 - val_accuracy: 0.9305 - val_loss: 0.2820\n",
      "Epoch 182/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.9416 - loss: 0.2470 - val_accuracy: 0.9305 - val_loss: 0.2820\n",
      "Epoch 183/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9388 - loss: 0.2547 - val_accuracy: 0.9305 - val_loss: 0.2827\n",
      "Epoch 184/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9365 - loss: 0.2613 - val_accuracy: 0.9305 - val_loss: 0.2827\n",
      "Epoch 185/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9456 - loss: 0.2354 - val_accuracy: 0.9305 - val_loss: 0.2809\n",
      "Epoch 186/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9399 - loss: 0.2515 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 187/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9445 - loss: 0.2388 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "Epoch 188/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9513 - loss: 0.2195 - val_accuracy: 0.9305 - val_loss: 0.2808\n",
      "Epoch 189/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9442 - loss: 0.2400 - val_accuracy: 0.9305 - val_loss: 0.2812\n",
      "Epoch 190/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.9399 - loss: 0.2517 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 191/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9405 - loss: 0.2503 - val_accuracy: 0.9305 - val_loss: 0.2822\n",
      "Epoch 192/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9415 - loss: 0.2473 - val_accuracy: 0.9305 - val_loss: 0.2816\n",
      "Epoch 193/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9406 - loss: 0.2495 - val_accuracy: 0.9305 - val_loss: 0.2813\n",
      "Epoch 194/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9471 - loss: 0.2316 - val_accuracy: 0.9305 - val_loss: 0.2814\n",
      "Epoch 195/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9433 - loss: 0.2420 - val_accuracy: 0.9305 - val_loss: 0.2832\n",
      "Epoch 196/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9438 - loss: 0.2407 - val_accuracy: 0.9305 - val_loss: 0.2816\n",
      "Epoch 197/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.9455 - loss: 0.2359 - val_accuracy: 0.9305 - val_loss: 0.2813\n",
      "Epoch 198/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9455 - loss: 0.2361 - val_accuracy: 0.9305 - val_loss: 0.2818\n",
      "Epoch 199/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9415 - loss: 0.2471 - val_accuracy: 0.9305 - val_loss: 0.2821\n",
      "Epoch 200/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9430 - loss: 0.2432 - val_accuracy: 0.9305 - val_loss: 0.2817\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9353 - loss: 0.2647\n",
      "L1 Regularization Test Accuracy: 0.9305\n"
     ]
    }
   ],
   "source": [
    "# Functional API Model with L1 Regularization\n",
    "# Define the input layer\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# Add layers with L1 regularization\n",
    "x = Dense(128, activation='relu', \n",
    "          kernel_regularizer=regularizers.l1(0.01))(inputs)\n",
    "\n",
    "x = Dense(64, activation='relu', \n",
    "          kernel_regularizer=regularizers.l1(0.01))(x)\n",
    "\n",
    "x = Dense(32, activation='relu', \n",
    "          kernel_regularizer=regularizers.l1(0.01))(x)\n",
    "\n",
    "# Add the output layer\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model by specifying inputs and outputs\n",
    "model_l1 = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model_l1.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_l1 = model_l1.fit(X_train, y_train, \n",
    "                           epochs=200, \n",
    "                           batch_size=32, \n",
    "                           validation_data=(X_valid, y_valid))\n",
    "\n",
    "# Evaluate the model after training\n",
    "loss_l1, accuracy_l1 = model_l1.evaluate(X_valid, y_valid)\n",
    "print(f\"L1 Regularization Test Accuracy: {accuracy_l1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9945281c-7dee-46cd-a7ea-c89cf0434f73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step - accuracy: 0.9447 - loss: 1.9348 - val_accuracy: 0.9305 - val_loss: 0.7274\n",
      "Epoch 2/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9454 - loss: 0.5520 - val_accuracy: 0.9305 - val_loss: 0.3756\n",
      "Epoch 3/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9439 - loss: 0.3042 - val_accuracy: 0.9305 - val_loss: 0.2930\n",
      "Epoch 4/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9369 - loss: 0.2538 - val_accuracy: 0.9305 - val_loss: 0.2688\n",
      "Epoch 5/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9436 - loss: 0.2238 - val_accuracy: 0.9305 - val_loss: 0.2566\n",
      "Epoch 6/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9441 - loss: 0.2139 - val_accuracy: 0.9305 - val_loss: 0.2556\n",
      "Epoch 7/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9400 - loss: 0.2222 - val_accuracy: 0.9305 - val_loss: 0.2499\n",
      "Epoch 8/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.9465 - loss: 0.2020 - val_accuracy: 0.9305 - val_loss: 0.2517\n",
      "Epoch 9/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.9421 - loss: 0.2109 - val_accuracy: 0.9305 - val_loss: 0.2486\n",
      "Epoch 10/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9435 - loss: 0.2064 - val_accuracy: 0.9305 - val_loss: 0.2473\n",
      "Epoch 11/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9392 - loss: 0.2206 - val_accuracy: 0.9305 - val_loss: 0.2485\n",
      "Epoch 12/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9436 - loss: 0.2064 - val_accuracy: 0.9305 - val_loss: 0.2516\n",
      "Epoch 13/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9428 - loss: 0.2090 - val_accuracy: 0.9305 - val_loss: 0.2571\n",
      "Epoch 14/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9451 - loss: 0.2075 - val_accuracy: 0.9305 - val_loss: 0.2493\n",
      "Epoch 15/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9394 - loss: 0.2176 - val_accuracy: 0.9305 - val_loss: 0.2484\n",
      "Epoch 16/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.9436 - loss: 0.2043 - val_accuracy: 0.9305 - val_loss: 0.2452\n",
      "Epoch 17/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9357 - loss: 0.2220 - val_accuracy: 0.9305 - val_loss: 0.2502\n",
      "Epoch 18/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - accuracy: 0.9372 - loss: 0.2180 - val_accuracy: 0.9305 - val_loss: 0.2487\n",
      "Epoch 19/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9425 - loss: 0.2102 - val_accuracy: 0.9305 - val_loss: 0.2575\n",
      "Epoch 20/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9475 - loss: 0.1936 - val_accuracy: 0.9305 - val_loss: 0.2529\n",
      "Epoch 21/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9428 - loss: 0.2033 - val_accuracy: 0.9305 - val_loss: 0.2466\n",
      "Epoch 22/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.9401 - loss: 0.2150 - val_accuracy: 0.9305 - val_loss: 0.2457\n",
      "Epoch 23/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9401 - loss: 0.2114 - val_accuracy: 0.9305 - val_loss: 0.2435\n",
      "Epoch 24/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9468 - loss: 0.1972 - val_accuracy: 0.9305 - val_loss: 0.2439\n",
      "Epoch 25/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9391 - loss: 0.2111 - val_accuracy: 0.9305 - val_loss: 0.2519\n",
      "Epoch 26/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.9388 - loss: 0.2156 - val_accuracy: 0.9305 - val_loss: 0.2485\n",
      "Epoch 27/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9451 - loss: 0.2030 - val_accuracy: 0.9305 - val_loss: 0.2473\n",
      "Epoch 28/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9440 - loss: 0.2018 - val_accuracy: 0.9305 - val_loss: 0.2476\n",
      "Epoch 29/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.9438 - loss: 0.1986 - val_accuracy: 0.9305 - val_loss: 0.2443\n",
      "Epoch 30/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9379 - loss: 0.2144 - val_accuracy: 0.9305 - val_loss: 0.2471\n",
      "Epoch 31/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9432 - loss: 0.1990 - val_accuracy: 0.9305 - val_loss: 0.2470\n",
      "Epoch 32/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.9414 - loss: 0.2123 - val_accuracy: 0.9305 - val_loss: 0.2477\n",
      "Epoch 33/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9445 - loss: 0.1950 - val_accuracy: 0.9305 - val_loss: 0.2494\n",
      "Epoch 34/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9435 - loss: 0.2022 - val_accuracy: 0.9305 - val_loss: 0.2458\n",
      "Epoch 35/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - accuracy: 0.9458 - loss: 0.1948 - val_accuracy: 0.9305 - val_loss: 0.2440\n",
      "Epoch 36/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9385 - loss: 0.2125 - val_accuracy: 0.9305 - val_loss: 0.2454\n",
      "Epoch 37/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9407 - loss: 0.2069 - val_accuracy: 0.9305 - val_loss: 0.2458\n",
      "Epoch 38/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9474 - loss: 0.1905 - val_accuracy: 0.9305 - val_loss: 0.2468\n",
      "Epoch 39/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9380 - loss: 0.2147 - val_accuracy: 0.9305 - val_loss: 0.2461\n",
      "Epoch 40/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9465 - loss: 0.1881 - val_accuracy: 0.9305 - val_loss: 0.2453\n",
      "Epoch 41/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9404 - loss: 0.2060 - val_accuracy: 0.9305 - val_loss: 0.2513\n",
      "Epoch 42/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9376 - loss: 0.2159 - val_accuracy: 0.9305 - val_loss: 0.2436\n",
      "Epoch 43/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - accuracy: 0.9442 - loss: 0.2003 - val_accuracy: 0.9305 - val_loss: 0.2499\n",
      "Epoch 44/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9422 - loss: 0.2027 - val_accuracy: 0.9305 - val_loss: 0.2453\n",
      "Epoch 45/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9417 - loss: 0.1988 - val_accuracy: 0.9305 - val_loss: 0.2421\n",
      "Epoch 46/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9489 - loss: 0.1889 - val_accuracy: 0.9305 - val_loss: 0.2449\n",
      "Epoch 47/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9432 - loss: 0.2003 - val_accuracy: 0.9305 - val_loss: 0.2424\n",
      "Epoch 48/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.9426 - loss: 0.2003 - val_accuracy: 0.9305 - val_loss: 0.2473\n",
      "Epoch 49/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9470 - loss: 0.1927 - val_accuracy: 0.9305 - val_loss: 0.2439\n",
      "Epoch 50/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9436 - loss: 0.2002 - val_accuracy: 0.9305 - val_loss: 0.2427\n",
      "Epoch 51/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9447 - loss: 0.1897 - val_accuracy: 0.9305 - val_loss: 0.2438\n",
      "Epoch 52/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9423 - loss: 0.2072 - val_accuracy: 0.9305 - val_loss: 0.2461\n",
      "Epoch 53/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9426 - loss: 0.2000 - val_accuracy: 0.9305 - val_loss: 0.2435\n",
      "Epoch 54/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9401 - loss: 0.2003 - val_accuracy: 0.9305 - val_loss: 0.2513\n",
      "Epoch 55/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9456 - loss: 0.1928 - val_accuracy: 0.9305 - val_loss: 0.2407\n",
      "Epoch 56/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9380 - loss: 0.2150 - val_accuracy: 0.9305 - val_loss: 0.2519\n",
      "Epoch 57/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9435 - loss: 0.1937 - val_accuracy: 0.9305 - val_loss: 0.2422\n",
      "Epoch 58/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9375 - loss: 0.2133 - val_accuracy: 0.9305 - val_loss: 0.2487\n",
      "Epoch 59/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9476 - loss: 0.1887 - val_accuracy: 0.9305 - val_loss: 0.2445\n",
      "Epoch 60/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - accuracy: 0.9463 - loss: 0.1984 - val_accuracy: 0.9305 - val_loss: 0.2429\n",
      "Epoch 61/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9396 - loss: 0.2084 - val_accuracy: 0.9305 - val_loss: 0.2466\n",
      "Epoch 62/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9379 - loss: 0.2103 - val_accuracy: 0.9305 - val_loss: 0.2423\n",
      "Epoch 63/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9386 - loss: 0.2094 - val_accuracy: 0.9305 - val_loss: 0.2506\n",
      "Epoch 64/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9439 - loss: 0.1969 - val_accuracy: 0.9305 - val_loss: 0.2450\n",
      "Epoch 65/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9437 - loss: 0.1967 - val_accuracy: 0.9305 - val_loss: 0.2437\n",
      "Epoch 66/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9398 - loss: 0.2039 - val_accuracy: 0.9305 - val_loss: 0.2395\n",
      "Epoch 67/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9388 - loss: 0.2042 - val_accuracy: 0.9305 - val_loss: 0.2399\n",
      "Epoch 68/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9468 - loss: 0.1927 - val_accuracy: 0.9305 - val_loss: 0.2411\n",
      "Epoch 69/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 0.9378 - loss: 0.2088 - val_accuracy: 0.9305 - val_loss: 0.2416\n",
      "Epoch 70/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9376 - loss: 0.2057 - val_accuracy: 0.9305 - val_loss: 0.2409\n",
      "Epoch 71/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9460 - loss: 0.1953 - val_accuracy: 0.9305 - val_loss: 0.2452\n",
      "Epoch 72/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9397 - loss: 0.2054 - val_accuracy: 0.9305 - val_loss: 0.2401\n",
      "Epoch 73/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9502 - loss: 0.1847 - val_accuracy: 0.9305 - val_loss: 0.2396\n",
      "Epoch 74/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9402 - loss: 0.2003 - val_accuracy: 0.9305 - val_loss: 0.2477\n",
      "Epoch 75/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9452 - loss: 0.1949 - val_accuracy: 0.9305 - val_loss: 0.2434\n",
      "Epoch 76/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9352 - loss: 0.2165 - val_accuracy: 0.9305 - val_loss: 0.2449\n",
      "Epoch 77/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9501 - loss: 0.1781 - val_accuracy: 0.9305 - val_loss: 0.2436\n",
      "Epoch 78/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9430 - loss: 0.1967 - val_accuracy: 0.9305 - val_loss: 0.2413\n",
      "Epoch 79/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9404 - loss: 0.2067 - val_accuracy: 0.9305 - val_loss: 0.2452\n",
      "Epoch 80/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9441 - loss: 0.1961 - val_accuracy: 0.9305 - val_loss: 0.2403\n",
      "Epoch 81/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9417 - loss: 0.2039 - val_accuracy: 0.9305 - val_loss: 0.2434\n",
      "Epoch 82/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9406 - loss: 0.2030 - val_accuracy: 0.9305 - val_loss: 0.2413\n",
      "Epoch 83/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9461 - loss: 0.1906 - val_accuracy: 0.9305 - val_loss: 0.2423\n",
      "Epoch 84/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9480 - loss: 0.1852 - val_accuracy: 0.9305 - val_loss: 0.2408\n",
      "Epoch 85/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9397 - loss: 0.2064 - val_accuracy: 0.9305 - val_loss: 0.2437\n",
      "Epoch 86/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9502 - loss: 0.1809 - val_accuracy: 0.9305 - val_loss: 0.2387\n",
      "Epoch 87/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9411 - loss: 0.2056 - val_accuracy: 0.9305 - val_loss: 0.2428\n",
      "Epoch 88/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9381 - loss: 0.2087 - val_accuracy: 0.9305 - val_loss: 0.2459\n",
      "Epoch 89/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9448 - loss: 0.1945 - val_accuracy: 0.9305 - val_loss: 0.2418\n",
      "Epoch 90/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9436 - loss: 0.1949 - val_accuracy: 0.9305 - val_loss: 0.2401\n",
      "Epoch 91/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9450 - loss: 0.1935 - val_accuracy: 0.9305 - val_loss: 0.2436\n",
      "Epoch 92/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9419 - loss: 0.1990 - val_accuracy: 0.9305 - val_loss: 0.2460\n",
      "Epoch 93/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9432 - loss: 0.1977 - val_accuracy: 0.9305 - val_loss: 0.2464\n",
      "Epoch 94/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9401 - loss: 0.2068 - val_accuracy: 0.9305 - val_loss: 0.2398\n",
      "Epoch 95/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9489 - loss: 0.1856 - val_accuracy: 0.9305 - val_loss: 0.2407\n",
      "Epoch 96/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9374 - loss: 0.2105 - val_accuracy: 0.9305 - val_loss: 0.2427\n",
      "Epoch 97/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9425 - loss: 0.1987 - val_accuracy: 0.9305 - val_loss: 0.2430\n",
      "Epoch 98/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9444 - loss: 0.1904 - val_accuracy: 0.9305 - val_loss: 0.2397\n",
      "Epoch 99/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9386 - loss: 0.2036 - val_accuracy: 0.9305 - val_loss: 0.2473\n",
      "Epoch 100/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9427 - loss: 0.1951 - val_accuracy: 0.9305 - val_loss: 0.2516\n",
      "Epoch 101/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9418 - loss: 0.2010 - val_accuracy: 0.9305 - val_loss: 0.2402\n",
      "Epoch 102/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.9423 - loss: 0.1970 - val_accuracy: 0.9305 - val_loss: 0.2384\n",
      "Epoch 103/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9442 - loss: 0.1963 - val_accuracy: 0.9305 - val_loss: 0.2385\n",
      "Epoch 104/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9414 - loss: 0.2025 - val_accuracy: 0.9305 - val_loss: 0.2428\n",
      "Epoch 105/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9378 - loss: 0.2042 - val_accuracy: 0.9305 - val_loss: 0.2437\n",
      "Epoch 106/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9429 - loss: 0.1980 - val_accuracy: 0.9305 - val_loss: 0.2571\n",
      "Epoch 107/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9389 - loss: 0.2080 - val_accuracy: 0.9305 - val_loss: 0.2439\n",
      "Epoch 108/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9389 - loss: 0.2054 - val_accuracy: 0.9305 - val_loss: 0.2470\n",
      "Epoch 109/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9455 - loss: 0.1904 - val_accuracy: 0.9305 - val_loss: 0.2414\n",
      "Epoch 110/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9432 - loss: 0.2026 - val_accuracy: 0.9305 - val_loss: 0.2450\n",
      "Epoch 111/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.9415 - loss: 0.2001 - val_accuracy: 0.9305 - val_loss: 0.2423\n",
      "Epoch 112/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9433 - loss: 0.1944 - val_accuracy: 0.9305 - val_loss: 0.2455\n",
      "Epoch 113/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9364 - loss: 0.2157 - val_accuracy: 0.9305 - val_loss: 0.2542\n",
      "Epoch 114/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9448 - loss: 0.1887 - val_accuracy: 0.9305 - val_loss: 0.2398\n",
      "Epoch 115/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9390 - loss: 0.2061 - val_accuracy: 0.9305 - val_loss: 0.2433\n",
      "Epoch 116/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9452 - loss: 0.1903 - val_accuracy: 0.9305 - val_loss: 0.2390\n",
      "Epoch 117/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9452 - loss: 0.1911 - val_accuracy: 0.9305 - val_loss: 0.2429\n",
      "Epoch 118/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9435 - loss: 0.1980 - val_accuracy: 0.9305 - val_loss: 0.2445\n",
      "Epoch 119/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9418 - loss: 0.1976 - val_accuracy: 0.9305 - val_loss: 0.2486\n",
      "Epoch 120/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9412 - loss: 0.2004 - val_accuracy: 0.9305 - val_loss: 0.2591\n",
      "Epoch 121/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9364 - loss: 0.2147 - val_accuracy: 0.9305 - val_loss: 0.2529\n",
      "Epoch 122/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9417 - loss: 0.2003 - val_accuracy: 0.9305 - val_loss: 0.2390\n",
      "Epoch 123/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.9433 - loss: 0.1937 - val_accuracy: 0.9305 - val_loss: 0.2418\n",
      "Epoch 124/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.9457 - loss: 0.1919 - val_accuracy: 0.9305 - val_loss: 0.2388\n",
      "Epoch 125/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9459 - loss: 0.1857 - val_accuracy: 0.9305 - val_loss: 0.2391\n",
      "Epoch 126/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9451 - loss: 0.1871 - val_accuracy: 0.9305 - val_loss: 0.2512\n",
      "Epoch 127/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.9393 - loss: 0.2057 - val_accuracy: 0.9305 - val_loss: 0.2448\n",
      "Epoch 128/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9385 - loss: 0.2079 - val_accuracy: 0.9305 - val_loss: 0.2442\n",
      "Epoch 129/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9423 - loss: 0.1951 - val_accuracy: 0.9305 - val_loss: 0.2403\n",
      "Epoch 130/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.9446 - loss: 0.1939 - val_accuracy: 0.9305 - val_loss: 0.2430\n",
      "Epoch 131/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9413 - loss: 0.1970 - val_accuracy: 0.9305 - val_loss: 0.2404\n",
      "Epoch 132/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9373 - loss: 0.2068 - val_accuracy: 0.9305 - val_loss: 0.2475\n",
      "Epoch 133/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9444 - loss: 0.1902 - val_accuracy: 0.9305 - val_loss: 0.2384\n",
      "Epoch 134/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9413 - loss: 0.1933 - val_accuracy: 0.9305 - val_loss: 0.2393\n",
      "Epoch 135/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9396 - loss: 0.2050 - val_accuracy: 0.9305 - val_loss: 0.2437\n",
      "Epoch 136/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9417 - loss: 0.1947 - val_accuracy: 0.9305 - val_loss: 0.2461\n",
      "Epoch 137/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9457 - loss: 0.1834 - val_accuracy: 0.9305 - val_loss: 0.2413\n",
      "Epoch 138/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9397 - loss: 0.2004 - val_accuracy: 0.9305 - val_loss: 0.2387\n",
      "Epoch 139/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.9400 - loss: 0.1992 - val_accuracy: 0.9305 - val_loss: 0.2389\n",
      "Epoch 140/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9449 - loss: 0.1903 - val_accuracy: 0.9305 - val_loss: 0.2391\n",
      "Epoch 141/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9427 - loss: 0.1959 - val_accuracy: 0.9305 - val_loss: 0.2454\n",
      "Epoch 142/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9494 - loss: 0.1818 - val_accuracy: 0.9305 - val_loss: 0.2382\n",
      "Epoch 143/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.9390 - loss: 0.2075 - val_accuracy: 0.9305 - val_loss: 0.2472\n",
      "Epoch 144/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.9435 - loss: 0.1962 - val_accuracy: 0.9305 - val_loss: 0.2488\n",
      "Epoch 145/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9429 - loss: 0.1952 - val_accuracy: 0.9305 - val_loss: 0.2412\n",
      "Epoch 146/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9410 - loss: 0.2034 - val_accuracy: 0.9305 - val_loss: 0.2392\n",
      "Epoch 147/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - accuracy: 0.9430 - loss: 0.1972 - val_accuracy: 0.9305 - val_loss: 0.2417\n",
      "Epoch 148/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9400 - loss: 0.2011 - val_accuracy: 0.9305 - val_loss: 0.2457\n",
      "Epoch 149/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9446 - loss: 0.1898 - val_accuracy: 0.9305 - val_loss: 0.2429\n",
      "Epoch 150/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.9398 - loss: 0.2021 - val_accuracy: 0.9305 - val_loss: 0.2413\n",
      "Epoch 151/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9417 - loss: 0.1947 - val_accuracy: 0.9305 - val_loss: 0.2411\n",
      "Epoch 152/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9496 - loss: 0.1769 - val_accuracy: 0.9305 - val_loss: 0.2433\n",
      "Epoch 153/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9391 - loss: 0.2023 - val_accuracy: 0.9305 - val_loss: 0.2406\n",
      "Epoch 154/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.9432 - loss: 0.1948 - val_accuracy: 0.9305 - val_loss: 0.2377\n",
      "Epoch 155/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9384 - loss: 0.2074 - val_accuracy: 0.9305 - val_loss: 0.2461\n",
      "Epoch 156/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.9469 - loss: 0.1894 - val_accuracy: 0.9305 - val_loss: 0.2442\n",
      "Epoch 157/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9412 - loss: 0.1982 - val_accuracy: 0.9305 - val_loss: 0.2397\n",
      "Epoch 158/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9397 - loss: 0.2023 - val_accuracy: 0.9305 - val_loss: 0.2428\n",
      "Epoch 159/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9421 - loss: 0.1979 - val_accuracy: 0.9305 - val_loss: 0.2416\n",
      "Epoch 160/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9375 - loss: 0.2063 - val_accuracy: 0.9305 - val_loss: 0.2419\n",
      "Epoch 161/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9452 - loss: 0.1904 - val_accuracy: 0.9305 - val_loss: 0.2419\n",
      "Epoch 162/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.9420 - loss: 0.1939 - val_accuracy: 0.9305 - val_loss: 0.2383\n",
      "Epoch 163/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9445 - loss: 0.1929 - val_accuracy: 0.9305 - val_loss: 0.2382\n",
      "Epoch 164/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9462 - loss: 0.1826 - val_accuracy: 0.9305 - val_loss: 0.2376\n",
      "Epoch 165/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9453 - loss: 0.1891 - val_accuracy: 0.9305 - val_loss: 0.2398\n",
      "Epoch 166/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9450 - loss: 0.1894 - val_accuracy: 0.9305 - val_loss: 0.2439\n",
      "Epoch 167/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.9444 - loss: 0.1919 - val_accuracy: 0.9305 - val_loss: 0.2416\n",
      "Epoch 168/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9398 - loss: 0.2014 - val_accuracy: 0.9305 - val_loss: 0.2411\n",
      "Epoch 169/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9435 - loss: 0.1925 - val_accuracy: 0.9305 - val_loss: 0.2402\n",
      "Epoch 170/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9441 - loss: 0.1901 - val_accuracy: 0.9305 - val_loss: 0.2394\n",
      "Epoch 171/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.9432 - loss: 0.1933 - val_accuracy: 0.9305 - val_loss: 0.2449\n",
      "Epoch 172/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9457 - loss: 0.1882 - val_accuracy: 0.9305 - val_loss: 0.2371\n",
      "Epoch 173/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9463 - loss: 0.1862 - val_accuracy: 0.9305 - val_loss: 0.2402\n",
      "Epoch 174/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9418 - loss: 0.1924 - val_accuracy: 0.9305 - val_loss: 0.2412\n",
      "Epoch 175/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9460 - loss: 0.1822 - val_accuracy: 0.9305 - val_loss: 0.2378\n",
      "Epoch 176/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9411 - loss: 0.1954 - val_accuracy: 0.9305 - val_loss: 0.2452\n",
      "Epoch 177/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9437 - loss: 0.1952 - val_accuracy: 0.9305 - val_loss: 0.2366\n",
      "Epoch 178/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.9485 - loss: 0.1808 - val_accuracy: 0.9305 - val_loss: 0.2353\n",
      "Epoch 179/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9379 - loss: 0.2080 - val_accuracy: 0.9305 - val_loss: 0.2447\n",
      "Epoch 180/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.9480 - loss: 0.1863 - val_accuracy: 0.9305 - val_loss: 0.2411\n",
      "Epoch 181/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.9443 - loss: 0.1898 - val_accuracy: 0.9305 - val_loss: 0.2410\n",
      "Epoch 182/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9506 - loss: 0.1753 - val_accuracy: 0.9305 - val_loss: 0.2418\n",
      "Epoch 183/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9431 - loss: 0.1950 - val_accuracy: 0.9305 - val_loss: 0.2418\n",
      "Epoch 184/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9399 - loss: 0.1925 - val_accuracy: 0.9305 - val_loss: 0.2379\n",
      "Epoch 185/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9444 - loss: 0.1876 - val_accuracy: 0.9305 - val_loss: 0.2411\n",
      "Epoch 186/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9406 - loss: 0.1974 - val_accuracy: 0.9305 - val_loss: 0.2416\n",
      "Epoch 187/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.9395 - loss: 0.2040 - val_accuracy: 0.9305 - val_loss: 0.2382\n",
      "Epoch 188/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9392 - loss: 0.2011 - val_accuracy: 0.9305 - val_loss: 0.2444\n",
      "Epoch 189/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9412 - loss: 0.1984 - val_accuracy: 0.9305 - val_loss: 0.2371\n",
      "Epoch 190/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9494 - loss: 0.1782 - val_accuracy: 0.9305 - val_loss: 0.2394\n",
      "Epoch 191/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9407 - loss: 0.1973 - val_accuracy: 0.9305 - val_loss: 0.2379\n",
      "Epoch 192/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.9466 - loss: 0.1824 - val_accuracy: 0.9305 - val_loss: 0.2395\n",
      "Epoch 193/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.9379 - loss: 0.2075 - val_accuracy: 0.9305 - val_loss: 0.2404\n",
      "Epoch 194/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9390 - loss: 0.2039 - val_accuracy: 0.9305 - val_loss: 0.2479\n",
      "Epoch 195/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9501 - loss: 0.1758 - val_accuracy: 0.9305 - val_loss: 0.2402\n",
      "Epoch 196/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.9484 - loss: 0.1814 - val_accuracy: 0.9305 - val_loss: 0.2382\n",
      "Epoch 197/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 0.9425 - loss: 0.2004 - val_accuracy: 0.9305 - val_loss: 0.2427\n",
      "Epoch 198/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9410 - loss: 0.2004 - val_accuracy: 0.9305 - val_loss: 0.2520\n",
      "Epoch 199/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - accuracy: 0.9360 - loss: 0.2037 - val_accuracy: 0.9305 - val_loss: 0.2421\n",
      "Epoch 200/200\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9484 - loss: 0.1834 - val_accuracy: 0.9305 - val_loss: 0.2437\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320us/step - accuracy: 0.9353 - loss: 0.2249\n",
      "L2 Regularization Test Accuracy: 0.9305\n"
     ]
    }
   ],
   "source": [
    "# Functional API Model with L2 Regularization\n",
    "# Define the input layer\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# Add layers with L2 regularization\n",
    "x = Dense(128, activation='relu', \n",
    "          kernel_regularizer=regularizers.l2(0.01))(inputs)\n",
    "\n",
    "x = Dense(64, activation='relu', \n",
    "          kernel_regularizer=regularizers.l2(0.01))(x)  \n",
    "\n",
    "x = Dense(32, activation='relu', \n",
    "          kernel_regularizer=regularizers.l2(0.01))(x)  \n",
    "\n",
    "# Add the output layer\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model by specifying inputs and outputs\n",
    "model_l2 = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model_l2.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_l2 = model_l2.fit(X_train, y_train, \n",
    "                           epochs=200, \n",
    "                           batch_size=32, \n",
    "                           validation_data=(X_valid, y_valid))\n",
    "\n",
    "# Evaluate the model after training\n",
    "loss_l2, accuracy_l2 = model_l2.evaluate(X_valid, y_valid)\n",
    "print(f\"L2 Regularization Test Accuracy: {accuracy_l2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97bc7a1a-9534-4815-9e93-d96726756b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding Regularization improved the model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1621bc0-e0f4-449e-a9c2-a34c1972276c",
   "metadata": {},
   "source": [
    "### Implementing on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37fd4fff-aae7-4fa4-a6fb-7fae3b0261cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9004 - loss: 13.4885 - val_accuracy: 0.9339 - val_loss: 1.7767\n",
      "Epoch 2/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9440 - loss: 0.9963 - val_accuracy: 0.9339 - val_loss: 0.3583\n",
      "Epoch 3/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9396 - loss: 0.3198 - val_accuracy: 0.9339 - val_loss: 0.2934\n",
      "Epoch 4/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.9470 - loss: 0.2531 - val_accuracy: 0.9339 - val_loss: 0.2764\n",
      "Epoch 5/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9433 - loss: 0.2484 - val_accuracy: 0.9339 - val_loss: 0.2698\n",
      "Epoch 6/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.9419 - loss: 0.2469 - val_accuracy: 0.9339 - val_loss: 0.2686\n",
      "Epoch 7/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9374 - loss: 0.2588 - val_accuracy: 0.9339 - val_loss: 0.2685\n",
      "Epoch 8/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9359 - loss: 0.2629 - val_accuracy: 0.9339 - val_loss: 0.2692\n",
      "Epoch 9/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9358 - loss: 0.2636 - val_accuracy: 0.9339 - val_loss: 0.2689\n",
      "Epoch 10/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9401 - loss: 0.2512 - val_accuracy: 0.9339 - val_loss: 0.2687\n",
      "Epoch 11/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 0.9444 - loss: 0.2393 - val_accuracy: 0.9339 - val_loss: 0.2684\n",
      "Epoch 12/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9426 - loss: 0.2444 - val_accuracy: 0.9339 - val_loss: 0.2686\n",
      "Epoch 13/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9355 - loss: 0.2639 - val_accuracy: 0.9339 - val_loss: 0.2694\n",
      "Epoch 14/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9416 - loss: 0.2473 - val_accuracy: 0.9339 - val_loss: 0.2690\n",
      "Epoch 15/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.9396 - loss: 0.2527 - val_accuracy: 0.9339 - val_loss: 0.2692\n",
      "Epoch 16/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9337 - loss: 0.2692 - val_accuracy: 0.9339 - val_loss: 0.2696\n",
      "Epoch 17/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9481 - loss: 0.2286 - val_accuracy: 0.9339 - val_loss: 0.2683\n",
      "Epoch 18/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9439 - loss: 0.2405 - val_accuracy: 0.9339 - val_loss: 0.2686\n",
      "Epoch 19/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - accuracy: 0.9420 - loss: 0.2459 - val_accuracy: 0.9339 - val_loss: 0.2687\n",
      "Epoch 20/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9445 - loss: 0.2389 - val_accuracy: 0.9339 - val_loss: 0.2685\n",
      "Epoch 21/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9396 - loss: 0.2525 - val_accuracy: 0.9339 - val_loss: 0.2691\n",
      "Epoch 22/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9489 - loss: 0.2265 - val_accuracy: 0.9339 - val_loss: 0.2682\n",
      "Epoch 23/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9438 - loss: 0.2412 - val_accuracy: 0.9339 - val_loss: 0.2690\n",
      "Epoch 24/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.9364 - loss: 0.2617 - val_accuracy: 0.9339 - val_loss: 0.2693\n",
      "Epoch 25/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9405 - loss: 0.2502 - val_accuracy: 0.9339 - val_loss: 0.2690\n",
      "Epoch 26/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9443 - loss: 0.2393 - val_accuracy: 0.9339 - val_loss: 0.2686\n",
      "Epoch 27/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9446 - loss: 0.2388 - val_accuracy: 0.9339 - val_loss: 0.2692\n",
      "Epoch 28/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.9472 - loss: 0.2317 - val_accuracy: 0.9339 - val_loss: 0.2688\n",
      "Epoch 29/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9428 - loss: 0.2437 - val_accuracy: 0.9339 - val_loss: 0.2685\n",
      "Epoch 30/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.9399 - loss: 0.2517 - val_accuracy: 0.9339 - val_loss: 0.2686\n",
      "Epoch 31/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9377 - loss: 0.2579 - val_accuracy: 0.9339 - val_loss: 0.2689\n",
      "Epoch 32/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9438 - loss: 0.2409 - val_accuracy: 0.9339 - val_loss: 0.2685\n",
      "Epoch 33/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.9473 - loss: 0.2313 - val_accuracy: 0.9339 - val_loss: 0.2684\n",
      "Epoch 34/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9350 - loss: 0.2651 - val_accuracy: 0.9339 - val_loss: 0.2692\n",
      "Epoch 35/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.9404 - loss: 0.2504 - val_accuracy: 0.9339 - val_loss: 0.2690\n",
      "Epoch 36/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.9401 - loss: 0.2514 - val_accuracy: 0.9339 - val_loss: 0.2690\n",
      "Epoch 37/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9489 - loss: 0.2264 - val_accuracy: 0.9339 - val_loss: 0.2683\n",
      "Epoch 38/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9439 - loss: 0.2408 - val_accuracy: 0.9339 - val_loss: 0.2687\n",
      "Epoch 39/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.9420 - loss: 0.2456 - val_accuracy: 0.9339 - val_loss: 0.2684\n",
      "Epoch 40/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.9369 - loss: 0.2601 - val_accuracy: 0.9339 - val_loss: 0.2694\n",
      "Epoch 41/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9449 - loss: 0.2386 - val_accuracy: 0.9339 - val_loss: 0.2686\n",
      "Epoch 42/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9413 - loss: 0.2477 - val_accuracy: 0.9339 - val_loss: 0.2685\n",
      "Epoch 43/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.9425 - loss: 0.2446 - val_accuracy: 0.9339 - val_loss: 0.2686\n",
      "Epoch 44/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9480 - loss: 0.2293 - val_accuracy: 0.9339 - val_loss: 0.2685\n",
      "Epoch 45/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9407 - loss: 0.2497 - val_accuracy: 0.9339 - val_loss: 0.2684\n",
      "Epoch 46/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9444 - loss: 0.2395 - val_accuracy: 0.9339 - val_loss: 0.2686\n",
      "Epoch 47/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.9409 - loss: 0.2489 - val_accuracy: 0.9339 - val_loss: 0.2687\n",
      "Epoch 48/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9457 - loss: 0.2359 - val_accuracy: 0.9339 - val_loss: 0.2685\n",
      "Epoch 49/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9414 - loss: 0.2477 - val_accuracy: 0.9339 - val_loss: 0.2688\n",
      "Epoch 50/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.9380 - loss: 0.2571 - val_accuracy: 0.9339 - val_loss: 0.2692\n",
      "Epoch 51/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9451 - loss: 0.2372 - val_accuracy: 0.9339 - val_loss: 0.2686\n",
      "Epoch 52/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9373 - loss: 0.2591 - val_accuracy: 0.9339 - val_loss: 0.2696\n",
      "Epoch 53/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9385 - loss: 0.2561 - val_accuracy: 0.9339 - val_loss: 0.2693\n",
      "Epoch 54/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.9397 - loss: 0.2524 - val_accuracy: 0.9339 - val_loss: 0.2693\n",
      "Epoch 55/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.9373 - loss: 0.2590 - val_accuracy: 0.9339 - val_loss: 0.2693\n",
      "Epoch 56/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9429 - loss: 0.2433 - val_accuracy: 0.9339 - val_loss: 0.2685\n",
      "Epoch 57/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9424 - loss: 0.2449 - val_accuracy: 0.9339 - val_loss: 0.2684\n",
      "Epoch 58/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.9434 - loss: 0.2424 - val_accuracy: 0.9339 - val_loss: 0.2688\n",
      "Epoch 59/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.9395 - loss: 0.2528 - val_accuracy: 0.9339 - val_loss: 0.2692\n",
      "Epoch 60/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9441 - loss: 0.2401 - val_accuracy: 0.9339 - val_loss: 0.2691\n",
      "Epoch 61/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9343 - loss: 0.2674 - val_accuracy: 0.9339 - val_loss: 0.2695\n",
      "Epoch 62/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9384 - loss: 0.2561 - val_accuracy: 0.9339 - val_loss: 0.2694\n",
      "Epoch 63/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.9419 - loss: 0.2463 - val_accuracy: 0.9339 - val_loss: 0.2687\n",
      "Epoch 64/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9352 - loss: 0.2646 - val_accuracy: 0.9339 - val_loss: 0.2697\n",
      "Epoch 65/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9439 - loss: 0.2404 - val_accuracy: 0.9339 - val_loss: 0.2689\n",
      "Epoch 66/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9391 - loss: 0.2540 - val_accuracy: 0.9339 - val_loss: 0.2691\n",
      "Epoch 67/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9414 - loss: 0.2480 - val_accuracy: 0.9339 - val_loss: 0.2686\n",
      "Epoch 68/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.9441 - loss: 0.2399 - val_accuracy: 0.9339 - val_loss: 0.2685\n",
      "Epoch 69/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9420 - loss: 0.2460 - val_accuracy: 0.9339 - val_loss: 0.2684\n",
      "Epoch 70/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9441 - loss: 0.2402 - val_accuracy: 0.9339 - val_loss: 0.2687\n",
      "Epoch 71/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9405 - loss: 0.2502 - val_accuracy: 0.9339 - val_loss: 0.2688\n",
      "Epoch 72/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.9387 - loss: 0.2551 - val_accuracy: 0.9339 - val_loss: 0.2689\n",
      "Epoch 73/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.9401 - loss: 0.2512 - val_accuracy: 0.9339 - val_loss: 0.2689\n",
      "Epoch 74/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.9443 - loss: 0.2394 - val_accuracy: 0.9339 - val_loss: 0.2688\n",
      "Epoch 75/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.9442 - loss: 0.2397 - val_accuracy: 0.9339 - val_loss: 0.2684\n",
      "Epoch 76/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.9449 - loss: 0.2380 - val_accuracy: 0.9339 - val_loss: 0.2688\n",
      "Epoch 77/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9399 - loss: 0.2521 - val_accuracy: 0.9339 - val_loss: 0.2687\n",
      "Epoch 78/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9424 - loss: 0.2446 - val_accuracy: 0.9339 - val_loss: 0.2682\n",
      "Epoch 79/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.9481 - loss: 0.2292 - val_accuracy: 0.9339 - val_loss: 0.2684\n",
      "Epoch 80/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9420 - loss: 0.2461 - val_accuracy: 0.9339 - val_loss: 0.2687\n",
      "Epoch 81/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.9448 - loss: 0.2377 - val_accuracy: 0.9339 - val_loss: 0.2686\n",
      "Epoch 82/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9471 - loss: 0.2317 - val_accuracy: 0.9339 - val_loss: 0.2687\n",
      "Epoch 83/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.9440 - loss: 0.2406 - val_accuracy: 0.9339 - val_loss: 0.2683\n",
      "Epoch 84/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9411 - loss: 0.2484 - val_accuracy: 0.9339 - val_loss: 0.2684\n",
      "Epoch 85/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.9473 - loss: 0.2310 - val_accuracy: 0.9339 - val_loss: 0.2685\n",
      "Epoch 86/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.9403 - loss: 0.2504 - val_accuracy: 0.9339 - val_loss: 0.2690\n",
      "Epoch 87/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9415 - loss: 0.2473 - val_accuracy: 0.9339 - val_loss: 0.2691\n",
      "Epoch 88/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.9424 - loss: 0.2453 - val_accuracy: 0.9339 - val_loss: 0.2689\n",
      "Epoch 89/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.9428 - loss: 0.2437 - val_accuracy: 0.9339 - val_loss: 0.2689\n",
      "Epoch 90/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.9451 - loss: 0.2373 - val_accuracy: 0.9339 - val_loss: 0.2683\n",
      "Epoch 91/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9374 - loss: 0.2582 - val_accuracy: 0.9339 - val_loss: 0.2695\n",
      "Epoch 92/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9434 - loss: 0.2418 - val_accuracy: 0.9339 - val_loss: 0.2690\n",
      "Epoch 93/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.9426 - loss: 0.2444 - val_accuracy: 0.9339 - val_loss: 0.2685\n",
      "Epoch 94/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.9396 - loss: 0.2523 - val_accuracy: 0.9339 - val_loss: 0.2688\n",
      "Epoch 95/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9451 - loss: 0.2370 - val_accuracy: 0.9339 - val_loss: 0.2683\n",
      "Epoch 96/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9436 - loss: 0.2412 - val_accuracy: 0.9339 - val_loss: 0.2686\n",
      "Epoch 97/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9511 - loss: 0.2205 - val_accuracy: 0.9339 - val_loss: 0.2683\n",
      "Epoch 98/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.9421 - loss: 0.2459 - val_accuracy: 0.9339 - val_loss: 0.2688\n",
      "Epoch 99/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.9435 - loss: 0.2417 - val_accuracy: 0.9339 - val_loss: 0.2685\n",
      "Epoch 100/100\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.9411 - loss: 0.2484 - val_accuracy: 0.9339 - val_loss: 0.2685\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275us/step\n"
     ]
    }
   ],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Prepare the test dataset and scale it\n",
    "X_test_scaled = scaler.transform(test)\n",
    "\n",
    "# Prepare the input for the model\n",
    "inputs_final = Input(shape=(X_scaled.shape[1],))\n",
    "\n",
    "# Add layers with L1 regularization\n",
    "x = Dense(128, activation='relu', \n",
    "          kernel_regularizer=regularizers.l1(0.01))(inputs_final) \n",
    "x = Dense(64, activation='relu', \n",
    "          kernel_regularizer=regularizers.l1(0.01))(x)\n",
    "x = Dense(32, activation='relu', \n",
    "          kernel_regularizer=regularizers.l1(0.01))(x)\n",
    "\n",
    "# Add the output layer\n",
    "outputs_final = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model by specifying inputs and outputs\n",
    "model_final = Model(inputs=inputs_final, outputs=outputs_final)\n",
    "\n",
    "# Compile the model\n",
    "model_final.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the entire dataset\n",
    "history_3 = model_final.fit(X_scaled, y, epochs=100, batch_size=32, validation_split = 0.2)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert predictions to binary (0 or 1)\n",
    "predictions_binary = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Compare with actual target values\n",
    "actual_targets = target['target'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97b33cf3-28c0-45f0-b611-a7f25d086cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.9155\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = (predictions_binary.flatten() == actual_targets).mean()\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19194eff-fff9-4f8a-ac20-8533c90df569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history_3.history['loss'], label='Train Loss')\n",
    "plt.plot(history_3.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss (Binary Classification)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a462cc03-4e1f-4edf-b5c9-880a43a1bcae",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Observations:\n",
    "#### The accuracy has been improved from 90 to 93 by adding regularization technique to the model. \n",
    "#### Both L1 and L2 showed same result here.\n",
    "#### The train and validation loss decreased initially and remained constant afterward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5fd01-c357-47e3-8525-e78180331d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bfe4ec-aefb-4dbf-8046-d977989003e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
